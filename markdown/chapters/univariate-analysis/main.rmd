---
output:
  pdf_document: default
  html_document:
    df_print: paged
fontsize: 12pt
documentclass: book
header-includes:
  \setlength{\parskip}{1em}
---

```{r setup, include=FALSE, warning=F}
knitr::opts_chunk$set(echo = F, warning=F, comment = NA)
```

```{r include = FALSE}
rm(list=ls())
library(readxl)
library(dplyr)
library(ggplot2)
library(rstatix)
library(BSDA)
library(gridExtra)
library(kableExtra)
library(lawstat)

for(i in 1:6){
    r <- assign(paste0("r",i), (as.data.frame(read_excel("C:/Users/Katie/OneDrive/Uni_Work_Year4/Project/Year-4-Project/survey responses/raw.xlsx", paste0("R - v",i)))))
    py <- assign(paste0("py",i), (as.data.frame(read_excel("C:/Users/Katie/OneDrive/Uni_Work_Year4/Project/Year-4-Project/survey responses/raw.xlsx", paste0("Py - v",i)))))
    assign(paste0("ver",i), rbind(r, py))
}

ver1 <- ver1[-1,]
r1 <- r1[-1,]
py1 <- py1[-1,]

names(ver1) <- c("timestamp", "consent", "age", "uni", "sp_aware", "obs_skl", "num_skl", "cblind", "vis_pro",
                 
                 "con_1", "con_2", "con_3", "con_4", 
                 "log_1", "log_2", "log_3", "log_4",
                 "trn_1", "trn_2", "trn_3", "trn_4",
  
                 "def_1", "def_2", "def_3", 
                 "nar_1", "nar_2", "nar_3", 
                 "wid_1", "wid_2", "wid_3",
                 "all_1", "all_2", "all_3",
  
                 "vir_sta_1", "vir_sta_2", "vir_sta_3", "vir_sta_4", 
                 "vir_dge_1", "vir_dge_2", "vir_dge_3", "vir_dge_4",
                 "sta_dge",
                 "a_cols_1", "a_cols_2", 
  
                 "sep_1a", "sep_1b", "sep_2",
                 "ab_trn_1a", "ab_trn_1b", "ab_trn_2", 
                 "ab_zro_1", "ab_zro_1b", "ab_zro_2",
  
                 "cd_trn",
                 "cd_zro"
                 )

names(r1) <- c("timestamp", "consent", "age", "uni", "sp_aware", "obs_skl", "num_skl", "cblind", "vis_pro",
                 
                 "con_1", "con_2", "con_3", "con_4", 
                 "log_1", "log_2", "log_3", "log_4",
                 "trn_1", "trn_2", "trn_3", "trn_4",
  
                 "def_1", "def_2", "def_3", 
                 "nar_1", "nar_2", "nar_3", 
                 "wid_1", "wid_2", "wid_3",
                 "all_1", "all_2", "all_3",
  
                 "vir_sta_1", "vir_sta_2", "vir_sta_3", "vir_sta_4", 
                 "vir_dge_1", "vir_dge_2", "vir_dge_3", "vir_dge_4",
                 "sta_dge",
                 "a_cols_1", "a_cols_2", 
  
                 "sep_1a", "sep_1b", "sep_2",
                 "ab_trn_1a", "ab_trn_1b", "ab_trn_2", 
                 "ab_zro_1", "ab_zro_1b", "ab_zro_2",
  
                 "cd_trn",
                 "cd_zro"
                 )

names(py1) <- c("timestamp", "consent", "age", "uni", "sp_aware", "obs_skl", "num_skl", "cblind", "vis_pro",
                 
                 "con_1", "con_2", "con_3", "con_4", 
                 "log_1", "log_2", "log_3", "log_4",
                 "trn_1", "trn_2", "trn_3", "trn_4",
  
                 "def_1", "def_2", "def_3", 
                 "nar_1", "nar_2", "nar_3", 
                 "wid_1", "wid_2", "wid_3",
                 "all_1", "all_2", "all_3",
  
                 "vir_sta_1", "vir_sta_2", "vir_sta_3", "vir_sta_4", 
                 "vir_dge_1", "vir_dge_2", "vir_dge_3", "vir_dge_4",
                 "sta_dge",
                 "a_cols_1", "a_cols_2", 
  
                 "sep_1a", "sep_1b", "sep_2",
                 "ab_trn_1a", "ab_trn_1b", "ab_trn_2", 
                 "ab_zro_1", "ab_zro_1b", "ab_zro_2",
  
                 "cd_trn",
                 "cd_zro"
                 )
###

names(ver2) <- c("timestamp", "consent", "age", "uni", "sp_aware", "obs_skl", "num_skl", "cblind", "vis_pro",
                 
                 "con_1", "con_2", "con_3", "con_4", 
                 "trn_1", "trn_2", "trn_3", "trn_4",
                 "log_1", "log_2", "log_3", "log_4",
                 
                 "def_1", "def_2", "def_3", 
                 "wid_1", "wid_2", "wid_3",
                 "nar_1", "nar_2", "nar_3", 
                 "all_1", "all_2", "all_3",
                 
                 "def_sta_1", "def_sta_2", "def_sta_3", "def_sta_4", 
                 "def_dge_1", "def_dge_2", "def_dge_3", "def_dge_4",
                 "sta_dge",
                 "b_cols_1", "b_cols_2", 
  
                 "sep_1a", "sep_1b", "sep_2",
                 "ab_zro_1", "ab_zro_1b", "ab_zro_2",
                 "ab_trn_1a", "ab_trn_1b", "ab_trn_2", 
  
                 "cd_trn",
                 "cd_zro"
                 )

names(r2) <- c("timestamp", "consent", "age", "uni", "sp_aware", "obs_skl", "num_skl", "cblind", "vis_pro",
                 
                 "con_1", "con_2", "con_3", "con_4", 
                 "trn_1", "trn_2", "trn_3", "trn_4",
                 "log_1", "log_2", "log_3", "log_4",
                 
                 "def_1", "def_2", "def_3", 
                 "wid_1", "wid_2", "wid_3",
                 "nar_1", "nar_2", "nar_3", 
                 "all_1", "all_2", "all_3",
                 
                 "def_sta_1", "def_sta_2", "def_sta_3", "def_sta_4", 
                 "def_dge_1", "def_dge_2", "def_dge_3", "def_dge_4",
                 "sta_dge",
                 "b_cols_1", "b_cols_2", 
  
                 "sep_1a", "sep_1b", "sep_2",
                 "ab_zro_1", "ab_zro_1b", "ab_zro_2",
                 "ab_trn_1a", "ab_trn_1b", "ab_trn_2", 
  
                 "cd_trn",
                 "cd_zro"
                 )

names(py2) <- c("timestamp", "consent", "age", "uni", "sp_aware", "obs_skl", "num_skl", "cblind", "vis_pro",
                 
                 "con_1", "con_2", "con_3", "con_4", 
                 "trn_1", "trn_2", "trn_3", "trn_4",
                 "log_1", "log_2", "log_3", "log_4",
                 
                 "def_1", "def_2", "def_3", 
                 "wid_1", "wid_2", "wid_3",
                 "nar_1", "nar_2", "nar_3", 
                 "all_1", "all_2", "all_3",
                 
                 "def_sta_1", "def_sta_2", "def_sta_3", "def_sta_4", 
                 "def_dge_1", "def_dge_2", "def_dge_3", "def_dge_4",
                 "sta_dge",
                 "b_cols_1", "b_cols_2", 
  
                 "sep_1a", "sep_1b", "sep_2",
                 "ab_zro_1", "ab_zro_1b", "ab_zro_2",
                 "ab_trn_1a", "ab_trn_1b", "ab_trn_2", 
  
                 "cd_trn",
                 "cd_zro"
                 )
###

names(ver3) <- c("timestamp", "consent", "age", "uni", "sp_aware", "obs_skl", "num_skl", "cblind", "vis_pro",
                 
                 "log_1", "log_2", "log_3", "log_4",
                 "con_1", "con_2", "con_3", "con_4", 
                 "trn_1", "trn_2", "trn_3", "trn_4",
                 
                 "nar_1", "nar_2", "nar_3", 
                 "def_1", "def_2", "def_3", 
                 "wid_1", "wid_2", "wid_3",  
                 "all_1", "all_2", "all_3",
                 
                 "def_dge_1", "def_dge_2", "def_dge_3", "def_dge_4",
                 "def_sta_1", "def_sta_2", "def_sta_3", "def_sta_4", 
                 "sta_dge",
                 "c_cols_1", "c_cols_2", 
  
                 "ab_trn_1a", "ab_trn_1b", "ab_trn_2", 
                 "sep_1a", "sep_1b", "sep_2",
                 "ab_zro_1", "ab_zro_1b", "ab_zro_2",                
  
                 "cd_zro",
                 "cd_trn"
                 )

names(r3) <- c("timestamp", "consent", "age", "uni", "sp_aware", "obs_skl", "num_skl", "cblind", "vis_pro",
                 
                 "log_1", "log_2", "log_3", "log_4",
                 "con_1", "con_2", "con_3", "con_4", 
                 "trn_1", "trn_2", "trn_3", "trn_4",
                 
                 "nar_1", "nar_2", "nar_3", 
                 "def_1", "def_2", "def_3", 
                 "wid_1", "wid_2", "wid_3",  
                 "all_1", "all_2", "all_3",
                 
                 "def_dge_1", "def_dge_2", "def_dge_3", "def_dge_4",
                 "def_sta_1", "def_sta_2", "def_sta_3", "def_sta_4", 
                 "sta_dge",
                 "c_cols_1", "c_cols_2", 
  
                 "ab_trn_1a", "ab_trn_1b", "ab_trn_2", 
                 "sep_1a", "sep_1b", "sep_2",
                 "ab_zro_1", "ab_zro_1b", "ab_zro_2",                
  
                 "cd_zro",
                 "cd_trn"
                 )

names(py3) <- c("timestamp", "consent", "age", "uni", "sp_aware", "obs_skl", "num_skl", "cblind", "vis_pro",
                 
                 "log_1", "log_2", "log_3", "log_4",
                 "con_1", "con_2", "con_3", "con_4", 
                 "trn_1", "trn_2", "trn_3", "trn_4",
                 
                 "nar_1", "nar_2", "nar_3", 
                 "def_1", "def_2", "def_3", 
                 "wid_1", "wid_2", "wid_3",  
                 "all_1", "all_2", "all_3",
                 
                 "def_dge_1", "def_dge_2", "def_dge_3", "def_dge_4",
                 "def_sta_1", "def_sta_2", "def_sta_3", "def_sta_4", 
                 "sta_dge",
                 "c_cols_1", "c_cols_2", 
  
                 "ab_trn_1a", "ab_trn_1b", "ab_trn_2", 
                 "sep_1a", "sep_1b", "sep_2",
                 "ab_zro_1", "ab_zro_1b", "ab_zro_2",                
  
                 "cd_zro",
                 "cd_trn"
                 )
###

names(ver4) <- c("timestamp", "consent", "age", "uni", "sp_aware", "obs_skl", "num_skl", "cblind", "vis_pro",
                 
                 "log_1", "log_2", "log_3", "log_4",
                 "trn_1", "trn_2", "trn_3", "trn_4",
                 "con_1", "con_2", "con_3", "con_4", 
  
                 "nar_1", "nar_2", "nar_3", 
                 "wid_1", "wid_2", "wid_3",
                 "def_1", "def_2", "def_3", 
                 "all_1", "all_2", "all_3",
  
                 "gr_sta_1", "gr_sta_2", "gr_sta_3", "gr_sta_4",
                 "gr_dge_1", "gr_dge_2", "gr_dge_3", "gr_dge_4",  
                 "sta_dge",
                 "d_cols_1", "d_cols_2", 
  
                 "ab_trn_1a", "ab_trn_1b", "ab_trn_2", 
                 "ab_zro_1", "ab_zro_1b", "ab_zro_2",
                 "sep_1a", "sep_1b", "sep_2",

                 "cd_trn",
                 "cd_zro"
                 )

names(r4) <- c("timestamp", "consent", "age", "uni", "sp_aware", "obs_skl", "num_skl", "cblind", "vis_pro",
                 
                 "log_1", "log_2", "log_3", "log_4",
                 "trn_1", "trn_2", "trn_3", "trn_4",
                 "con_1", "con_2", "con_3", "con_4", 
  
                 "nar_1", "nar_2", "nar_3", 
                 "wid_1", "wid_2", "wid_3",
                 "def_1", "def_2", "def_3", 
                 "all_1", "all_2", "all_3",
  
                 "gr_sta_1", "gr_sta_2", "gr_sta_3", "gr_sta_4",
                 "gr_dge_1", "gr_dge_2", "gr_dge_3", "gr_dge_4",  
                 "sta_dge",
                 "d_cols_1", "d_cols_2", 
  
                 "ab_trn_1a", "ab_trn_1b", "ab_trn_2", 
                 "ab_zro_1", "ab_zro_1b", "ab_zro_2",
                 "sep_1a", "sep_1b", "sep_2",

                 "cd_trn",
                 "cd_zro"
                 )

names(py4) <- c("timestamp", "consent", "age", "uni", "sp_aware", "obs_skl", "num_skl", "cblind", "vis_pro",
                 
                 "log_1", "log_2", "log_3", "log_4",
                 "trn_1", "trn_2", "trn_3", "trn_4",
                 "con_1", "con_2", "con_3", "con_4", 
  
                 "nar_1", "nar_2", "nar_3", 
                 "wid_1", "wid_2", "wid_3",
                 "def_1", "def_2", "def_3", 
                 "all_1", "all_2", "all_3",
  
                 "gr_sta_1", "gr_sta_2", "gr_sta_3", "gr_sta_4",
                 "gr_dge_1", "gr_dge_2", "gr_dge_3", "gr_dge_4",  
                 "sta_dge",
                 "d_cols_1", "d_cols_2", 
  
                 "ab_trn_1a", "ab_trn_1b", "ab_trn_2", 
                 "ab_zro_1", "ab_zro_1b", "ab_zro_2",
                 "sep_1a", "sep_1b", "sep_2",

                 "cd_trn",
                 "cd_zro"
                 )
###

names(ver5) <- c("timestamp", "consent", "age", "uni", "sp_aware", "obs_skl", "num_skl", "cblind", "vis_pro",
                 
                 "trn_1", "trn_2", "trn_3", "trn_4",
                 "con_1", "con_2", "con_3", "con_4",
                 "log_1", "log_2", "log_3", "log_4", 
                 
                 "wid_1", "wid_2", "wid_3",
                 "def_1", "def_2", "def_3", 
                 "nar_1", "nar_2", "nar_3", 
                 "all_1", "all_2", "all_3",
  
                 "vir_dge_1", "vir_dge_2", "vir_dge_3", "vir_dge_4",
                 "vir_sta_1", "vir_sta_2", "vir_sta_3", "vir_sta_4", 
                 "sta_dge",
                 "e_cols_1", "e_cols_2", 
  
                 "ab_zro_1", "ab_zro_1b", "ab_zro_2",
                 "sep_1a", "sep_1b", "sep_2",
                 "ab_trn_1a", "ab_trn_1b", "ab_trn_2", 
                 
                 "cd_zro",
                 "cd_trn"
                 )

names(r5) <- c("timestamp", "consent", "age", "uni", "sp_aware", "obs_skl", "num_skl", "cblind", "vis_pro",
                 
                 "trn_1", "trn_2", "trn_3", "trn_4",
                 "con_1", "con_2", "con_3", "con_4",
                 "log_1", "log_2", "log_3", "log_4", 
                 
                 "wid_1", "wid_2", "wid_3",
                 "def_1", "def_2", "def_3", 
                 "nar_1", "nar_2", "nar_3", 
                 "all_1", "all_2", "all_3",
  
                 "vir_dge_1", "vir_dge_2", "vir_dge_3", "vir_dge_4",
                 "vir_sta_1", "vir_sta_2", "vir_sta_3", "vir_sta_4", 
                 "sta_dge",
                 "e_cols_1", "e_cols_2", 
  
                 "ab_zro_1", "ab_zro_1b", "ab_zro_2",
                 "sep_1a", "sep_1b", "sep_2",
                 "ab_trn_1a", "ab_trn_1b", "ab_trn_2", 
                 
                 "cd_zro",
                 "cd_trn"
                 )

names(py5) <- c("timestamp", "consent", "age", "uni", "sp_aware", "obs_skl", "num_skl", "cblind", "vis_pro",
                 
                 "trn_1", "trn_2", "trn_3", "trn_4",
                 "con_1", "con_2", "con_3", "con_4",
                 "log_1", "log_2", "log_3", "log_4", 
                 
                 "wid_1", "wid_2", "wid_3",
                 "def_1", "def_2", "def_3", 
                 "nar_1", "nar_2", "nar_3", 
                 "all_1", "all_2", "all_3",
  
                 "vir_dge_1", "vir_dge_2", "vir_dge_3", "vir_dge_4",
                 "vir_sta_1", "vir_sta_2", "vir_sta_3", "vir_sta_4", 
                 "sta_dge",
                 "e_cols_1", "e_cols_2", 
  
                 "ab_zro_1", "ab_zro_1b", "ab_zro_2",
                 "sep_1a", "sep_1b", "sep_2",
                 "ab_trn_1a", "ab_trn_1b", "ab_trn_2", 
                 
                 "cd_zro",
                 "cd_trn"
                 )
###

names(ver6) <- c("timestamp", "consent", "age", "uni", "sp_aware", "obs_skl", "num_skl", "cblind", "vis_pro",
                 
                 "trn_1", "trn_2", "trn_3", "trn_4",
                 "log_1", "log_2", "log_3", "log_4", 
                 "con_1", "con_2", "con_3", "con_4",
                 
                 "wid_1", "wid_2", "wid_3",
                 "nar_1", "nar_2", "nar_3", 
                 "def_1", "def_2", "def_3", 
                 "all_1", "all_2", "all_3",
  
                 "gr_dge_1", "gr_dge_2", "gr_dge_3", "gr_dge_4",
                 "gr_sta_1", "gr_sta_2", "gr_sta_3", "gr_sta_4", 
                 "sta_dge",
                 "f_cols_1", "f_cols_2", 
  
                 "ab_zro_1", "ab_zro_1b", "ab_zro_2",
                 "ab_trn_1a", "ab_trn_1b", "ab_trn_2", 
                 "sep_1a", "sep_1b", "sep_2",
                 
                 "cd_zro",
                 "cd_trn"
                 )
                 
names(r6) <- c("timestamp", "consent", "age", "uni", "sp_aware", "obs_skl", "num_skl", "cblind", "vis_pro",
                 
                 "trn_1", "trn_2", "trn_3", "trn_4",
                 "log_1", "log_2", "log_3", "log_4", 
                 "con_1", "con_2", "con_3", "con_4",
                 
                 "wid_1", "wid_2", "wid_3",
                 "nar_1", "nar_2", "nar_3", 
                 "def_1", "def_2", "def_3", 
                 "all_1", "all_2", "all_3",
  
                 "gr_dge_1", "gr_dge_2", "gr_dge_3", "gr_dge_4",
                 "gr_sta_1", "gr_sta_2", "gr_sta_3", "gr_sta_4", 
                 "sta_dge",
                 "f_cols_1", "f_cols_2", 
  
                 "ab_zro_1", "ab_zro_1b", "ab_zro_2",
                 "ab_trn_1a", "ab_trn_1b", "ab_trn_2", 
                 "sep_1a", "sep_1b", "sep_2",
                 
                 "cd_zro",
                 "cd_trn"
                 )

names(py6) <- c("timestamp", "consent", "age", "uni", "sp_aware", "obs_skl", "num_skl", "cblind", "vis_pro",
                 
                 "trn_1", "trn_2", "trn_3", "trn_4",
                 "log_1", "log_2", "log_3", "log_4", 
                 "con_1", "con_2", "con_3", "con_4",
                 
                 "wid_1", "wid_2", "wid_3",
                 "nar_1", "nar_2", "nar_3", 
                 "def_1", "def_2", "def_3", 
                 "all_1", "all_2", "all_3",
  
                 "gr_dge_1", "gr_dge_2", "gr_dge_3", "gr_dge_4",
                 "gr_sta_1", "gr_sta_2", "gr_sta_3", "gr_sta_4", 
                 "sta_dge",
                 "f_cols_1", "f_cols_2", 
  
                 "ab_zro_1", "ab_zro_1b", "ab_zro_2",
                 "ab_trn_1a", "ab_trn_1b", "ab_trn_2", 
                 "sep_1a", "sep_1b", "sep_2",
                 
                 "cd_zro",
                 "cd_trn"
                 )
### Y SCALES 
ctrl_y_scale <- rbind(ver1[,c(4:7, 10:13)], ver2[,c(4:7, 10:13)], ver3[,c(4:7, 14:17)], ver4[,c(4:7, 18:21)], ver5[,c(4:7, 14:17)], ver6[,c(4:7, 18:21)])
log_y_scale <- rbind(ver1[,c(4:7, 14:17)], ver2[,c(4:7, 18:21)], ver3[,c(4:7, 10:13)], ver4[,c(4:7, 10:13)], ver5[,c(4:7, 18:21)], ver6[,c(4:7, 14:17)])
trnc_y_scale <- rbind(ver1[,c(4:7, 18:21)], ver2[,c(4:7, 14:17)], ver3[,c(4:7, 18:21)], ver4[,c(4:7, 14:17)], ver5[,c(4:7, 10:13)], ver6[,c(4:7, 10:13)])


### ASPECT RATIO
def_ratio <- rbind(ver1[,c(4:7, 22:24)], ver2[,c(4:7, 22:24)], ver3[,c(4:7, 25:27)], ver4[,c(4:7, 28:30)], ver5[,c(4:7, 25:27)], ver6[,c(4:7, 28:30)])
nar_ratio <- rbind(ver1[,c(4:7, 25:27)], ver2[,c(4:7, 28:30)], ver3[,c(4:7, 22:24)], ver4[,c(4:7, 22:24)], ver5[,c(4:7, 28:30)], ver6[,c(4:7, 25:27)])
wid_ratio <- rbind(ver1[,c(4:7, 28:30)], ver2[,c(4:7, 25:27)], ver3[,c(4:7, 28:30)], ver4[,c(4:7, 25:27)], ver5[,c(4:7, 22:24)], ver6[,c(4:7, 22:24)])


for(i in 1:dim(ver1)[1]){
  if(ver1$all_1[i]=="A"){
    ver1$all_1[i] <- "Default"
  }
  if(ver1$all_1[i]=="B"){
    ver1$all_1[i] <- "Narrower"
  }
  if(ver1$all_1[i]=="C"){
    ver1$all_1[i] <- "Wider"
  }
  
  if(ver1$all_2[i]=="A"){
    ver1$all_2[i] <- "Default"
  }
  if(ver1$all_2[i]=="B"){
    ver1$all_2[i] <- "Narrower"
  }
  if(ver1$all_2[i]=="C"){
    ver1$all_2[i] <- "Wider"
  }
  
  if(ver1$all_3[i]=="A"){
    ver1$all_3[i] <- "Default"
  }
  if(ver1$all_3[i]=="B"){
    ver1$all_3[i] <- "Narrower"
  }
  if(ver1$all_3[i]=="C"){
    ver1$all_3[i] <- "Wider"
  }
}

for(i in 1:dim(ver2)[1]){
  if(ver2$all_1[i]=="A"){
    ver2$all_1[i] <- "Default"
  }
  if(ver2$all_1[i]=="C"){
    ver2$all_1[i] <- "Narrower"
  }
  if(ver2$all_1[i]=="B"){
    ver2$all_1[i] <- "Wider"
  }
  
  if(ver2$all_2[i]=="A"){
    ver2$all_2[i] <- "Default"
  }
  if(ver2$all_2[i]=="C"){
    ver2$all_2[i] <- "Narrower"
  }
  if(ver2$all_2[i]=="B"){
    ver2$all_2[i] <- "Wider"
  }
  
  if(ver2$all_3[i]=="A"){
    ver2$all_3[i] <- "Default"
  }
  if(ver2$all_3[i]=="C"){
    ver2$all_3[i] <- "Narrower"
  }
  if(ver2$all_3[i]=="B"){
    ver2$all_3[i] <- "Wider"
  }
}

for(i in 1:dim(ver3)[1]){
  if(ver3$all_1[i]=="B"){
    ver3$all_1[i] <- "Default"
  }
  if(ver3$all_1[i]=="A"){
    ver3$all_1[i] <- "Narrower"
  }
  if(ver3$all_1[i]=="C"){
    ver3$all_1[i] <- "Wider"
  }
  
  if(ver3$all_2[i]=="B"){
    ver3$all_2[i] <- "Default"
  }
  if(ver3$all_2[i]=="A"){
    ver3$all_2[i] <- "Narrower"
  }
  if(ver3$all_2[i]=="C"){
    ver3$all_2[i] <- "Wider"
  }
  
  if(ver3$all_3[i]=="B"){
    ver3$all_3[i] <- "Default"
  }
  if(ver3$all_3[i]=="A"){
    ver3$all_3[i] <- "Narrower"
  }
  if(ver3$all_3[i]=="C"){
    ver3$all_3[i] <- "Wider"
  }
}

for(i in 1:dim(ver4)[1]){
  if(ver4$all_1[i]=="B"){
    ver4$all_1[i] <- "Default"
  }
  if(ver4$all_1[i]=="C"){
    ver4$all_1[i] <- "Narrower"
  }
  if(ver4$all_1[i]=="A"){
    ver4$all_1[i] <- "Wider"
  }
  
  if(ver4$all_2[i]=="B"){
    ver4$all_2[i] <- "Default"
  }
  if(ver4$all_2[i]=="C"){
    ver4$all_2[i] <- "Narrower"
  }
  if(ver4$all_2[i]=="A"){
    ver4$all_2[i] <- "Wider"
  }
  
  if(ver4$all_3[i]=="B"){
    ver4$all_3[i] <- "Default"
  }
  if(ver4$all_3[i]=="C"){
    ver4$all_3[i] <- "Narrower"
  }
  if(ver4$all_3[i]=="A"){
    ver4$all_3[i] <- "Wider"
  }
}

ver5$all_1[is.na(ver5$all_1)] <- "none"

for(i in 1:dim(ver5)[1]){
  
  if(ver5$all_1[i]=="C"){
    ver5$all_1[i] <- "Default"
  }
  if(ver5$all_1[i]=="A"){
    ver5$all_1[i] <- "Narrower"
  }
  if(ver5$all_1[i]=="B"){
    ver5$all_1[i] <- "Wider"
  }
  
  if(ver5$all_2[i]=="C"){
    ver5$all_2[i] <- "Default"
  }
  if(ver5$all_2[i]=="A"){
    ver5$all_2[i] <- "Narrower"
  }
  if(ver5$all_2[i]=="B"){
    ver5$all_2[i] <- "Wider"
  }
  
  if(ver5$all_3[i]=="C"){
    ver5$all_3[i] <- "Default"
  }
  if(ver5$all_3[i]=="A"){
    ver5$all_3[i] <- "Narrower"
  }
  if(ver5$all_3[i]=="B"){
    ver5$all_3[i] <- "Wider"
  }
}

for(i in 1:dim(ver6)[1]){
  if(ver6$all_1[i]=="C"){
    ver6$all_1[i] <- "Default"
  }
  if(ver6$all_1[i]=="B"){
    ver6$all_1[i] <- "Narrower"
  }
  if(ver6$all_1[i]=="A"){
    ver6$all_1[i] <- "Wider"
  }
  
  if(ver6$all_2[i]=="C"){
    ver6$all_2[i] <- "Default"
  }
  if(ver6$all_2[i]=="B"){
    ver6$all_2[i] <- "Narrower"
  }
  if(ver6$all_2[i]=="A"){
    ver6$all_2[i] <- "Wider"
  }
  
  if(ver6$all_3[i]=="C"){
    ver6$all_3[i] <- "Default"
  }
  if(ver6$all_3[i]=="B"){
    ver6$all_3[i] <- "Narrower"
  }
  if(ver6$all_3[i]=="A"){
    ver6$all_3[i] <- "Wider"
  }
}

comp_ratio <- rbind(ver1[,c(4:7, 31:33)], ver2[,c(4:7, 31:33)], ver3[,c(4:7, 31:33)], ver4[,c(4:7, 31:33)], ver5[,c(4:7, 31:33)], ver6[,c(4:7, 31:33)])


### STACKED
vir_stacked <- rbind(ver1[,c(4:7, 34:41)], ver5[,c(4:7, 34:41)])
def_stacked <- rbind(ver2[,c(4:7, 34:41)], ver3[,c(4:7, 34:41)])
gr_stacked <- rbind(ver4[,c(4:7, 34:41)], ver6[,c(4:7, 34:41)])

set_a <- ver1[,c(4:7, 42:44)]
set_b <- ver2[,c(4:7, 42:44)]
set_c <- ver3[,c(4:7, 42:44)]
set_d <- ver4[,c(4:7, 42:44)]
set_e <- ver5[,c(4:7, 42:44)]
set_f <- ver6[,c(4:7, 42:44)]

### SALES_AB
ab_sep <- rbind(ver1[,c(4:7, 45:47)], ver2[,c(4:7, 45:47)], ver3[,c(4:7, 48:50)], ver4[,c(4:7, 51:53)], ver5[,c(4:7, 48:50)], ver6[,c(4:7, 51:53)])

ab_trn <- rbind(ver1[,c(4:7, 48:50)], ver2[,c(4:7, 51:53)], ver3[,c(4:7, 45:47)], ver4[,c(4:7, 45:47)], ver5[,c(4:7, 51:53)], ver6[,c(4:7, 48:50)])

ab_zero <- rbind(ver1[,c(4:7, 51:53)], ver2[,c(4:7, 48:50)], ver3[,c(4:7, 51:53)], ver4[,c(4:7, 48:50)], ver5[,c(4:7, 45:47)], ver6[,c(4:7, 45:47)])


### SALES_CD
cd_trn <- rbind(ver1[,c(4:7, 54)], ver2[,c(4:7, 54)], ver3[,c(4:7, 55)], ver4[,c(4:7, 54)], ver5[,c(4:7, 55)], ver6[,c(4:7, 55)])

cd_zro <- rbind(ver1[,c(4:7, 55)], ver2[,c(4:7, 55)], ver3[,c(4:7, 54)], ver4[,c(4:7, 55)], ver5[,c(4:7, 54)], ver6[,c(4:7, 54)])



```

This chapter will discuss basic univariate analysis and summary statistics from the survey results, alongside what could be inferred from these. We will look at each section individually and perform multiple initial comparisons whereby we subset for various factors, such as the language used to make the plots, and the order in which plots have been presented.

First we will look at the summary statistics for each of the survey questions for the whole population, alongside box plots and density plots to gain an overview of the shape of the data and spread of values. Each table of summary statistics presents columns for the three plot types; the control plot, the truncated plot, and the logarithmic plot, respectively in that order. Note that sample size, n, and summary statistics are given after removing NA values. In the chapter 3 we will delve deeper into the data, sub-setting for various groups and performing comparisons between these groups to ascertain whether different demographic or population factors have an effect on responses.

\subsection{Ninja Warrior - Part 1}

The first part of the survey consisted of showing the respondents three bar plots representing data regarding how many times four obstacles were used throughout 10 seasons of American Ninja Warrior. The three presented visualisations all showed the same raw data, but used three different y-axis scalings in order to assess whether changing this scale in these ways affects viewer interpretation. The questions asked were designed to test the effect of scale on both reading off exact values and gauging differences in values. Each respondent was asked four questions; two free form answer and two multiple choice. The use of free form answers did result in occasional non-valid answers, such as statements along the lines of "Don't know" when a number was required. Many people also opted to write a number between 0 and 1 when a percentage was required, but these will not be considered invalid, as there were a large number of responses of this type, but rather we will assume that any number between 0 and 1 is considered as the corresponding percentage. Ie. an answer of 0.5 will be considered as 50%. 



\vspace{5cm}

**Approximately many times would you say the 'Salmon Ladder' was used?**

This question, the first of the survey, asked participants to type the how many times Salmon Ladder was used, based on the bar plot. The `correct' answer, or rather the true height of the corresponding bar, was 42. There were three invalid answers in these responses; one for the R versions of the survey and two for the Python versions. The invalid response in the R survey was '41/42', which we will take to be 41.5, and the invalid Python responses were given as 'Don't know' and 'Next to none.'. These two will be considered as 'NA' responses and thus discounted from the analysis of this question. These responses will. however, still be useful in our investigation; both were entered for the logarithmically scaled plot made in Python. The default log scaling in Python uses standard form notation, which perhaps these two participants were less familiar with. Similarly, there were two answers of '10^15' and '10^9', again potentially pointing towards the respondents being less familiar with this notation. 

Below we see the summary statistics for the overall population, where we have taken the '41/42' response as 41.5 and omitted the two invalid text answers as well as an additional NA response and thus obtain a sample size of 67.

```{r echo=F}
control <- ctrl_y_scale$con_1
control[which(control == "41/42")] <- # take midpoint of two values
control <- na.exclude(as.numeric(control))
 
truncated <- as.numeric(trnc_y_scale$trn_1)

logarithmic <- log_y_scale$log_1
logarithmic[which(logarithmic == "Don't know")] <- NA
logarithmic[which(logarithmic == "Next to none.")] <- NA
logarithmic[which(logarithmic == "10^15")] <- 1e+15
logarithmic[which(logarithmic == "10^9")] <- 1e+9
logarithmic <- as.numeric(na.exclude(logarithmic))

y_scale_1_all <- cbind(control, truncated, logarithmic)
```

The table below presents the total population summary statistics for the  for the first question. 

```{r echo=F}
noquote(paste('n (control) =', length(na.exclude(control))))
noquote(paste('n (truncated) =', length(na.exclude(truncated))))
noquote(paste('n (logarithmic) =', length(na.exclude(logarithmic))))
noquote(rbind(summary(y_scale_1_all), c(paste0('Var    :', round(var(control), 3)), paste0('Var    :', round(var(truncated), 3)), paste0('Var    :', round(var(logarithmic, na.rm=T), 3)))))
```

```{r include=F}
var(control)
var(truncated)
var(logarithmic)
```

We can see that for the control and truncated plots we have means 41.21 and 41.35 respectively and both have median 41, which at first glance do not appear significantly different from the true value of 42. To investigate this further we will run some statistical tests. These two sets also both have a range of 5, with minimums of 40 and maximums of 45, giving a fairly compact spread of data around the medium, and meaning that all respondents were in roughly the correct area. We also note that the means and medians of this data lie just below the true value, from which could be inferred that respondents tended to under-estimate. Although, the interquartile range does contain 42, so this may be a small underestimation. These two sets of responses also have very similar variances, at 0.742 and 0.753 respectively.

The mean of the responses for the log plot, on the other hand, is much higher at 1.493e+13 with the median much smaller in magnitude than this. In fact, the median is lower than for the control and truncated plots despite the mean being higher. We also have a very big range of $[9,1\times10^{15}]$, meaning some respondents inferred very different values from the plot than others. We see, however, that the interquartile range is much smaller, given as $[30, 40]$. This is still larger than the range for the control and truncated plot, but shows that the middle 50% of the data lies in this range. We also note that the 42 does not lie in this range but rather above it, perhaps once signifying a more significant respondent underestimation, despite the values at the upper end of the range being many orders of magnitude higher than the true value. In statistical terms, these will be considered outliers, but will still provide important insight with regard to the reasoning behind these outliers occurring. The large values at the extreme ends of the distribution also means the variance is very large, at $1.49\times10^{28}$.


To decide if t-tests are applicable here we will first look at the distribution of these variables before running Shapiro-Wilk tests of normality. Below we can see a density plot depicting the distributions of the values for the control and truncated plots.

```{r echo=F, fig.cap = "Density plot showing distributions of responses regarding the control and truncated plots"}

brks <- c("Control", "Truncated", "Logarithmic")
vals <- c("#1c9e77", "#d95f02", "#7570b3")

ggplot() +
  geom_density(data = as.data.frame(control), aes(x=control, col = "Control"))+
  geom_density(data = as.data.frame(truncated), aes(x=truncated, col = "Truncated"))+
  labs(x="Response", y="Density")+
  annotate("text", x=44, y = 0.66, label="Approximately many times would you say the", size = 4)+
  annotate("text", x=43.7, y = 0.62, label="'Salmon Ladder' was used?", size = 4)+
  annotate("text", x=43.7, y = 0.58, label="Whole population (n=70)", size = 3)+
  scale_colour_manual(breaks = brks[1:2], values = vals[1:2])+
  theme_classic()

```
The two distributions are very similarly shaped, and neither appears similar to a Gaussian curve, hence it is likely that they will violate the normality condition of a t-test. To confirm this hypothesis, Shapiro-Wilk tests for normality are performed. \newline
\textbf{Control Plot}
```{r echo=F}
shapiro.test(control)
```

\textbf{Truncated Plot}
```{r echo=F}
shapiro.test(truncated)
```

For both the control plot and truncated plot responses, the Shapiro-Wilk tests give $p << 0.05$, and thus we reject the hypothesis that these data are normal, and so they do, in fact, violate the normality condition required for a one-sample t-test.

One alternative to using a t-test is to use a Wilcoxon-Mann-Whitney (WMW) test. Note however that this test requires a symmetric distribution with even spread of values about the median. We see below, and from the density plot, that this isn't the case. \newline



\textbf{Control Plot}
```{r}
control <- na.exclude(control)
noquote(paste("Median:", median(control)))
noquote(paste("Number of observations below median:", length(control[which(control < median(control))])))
noquote(paste("Number of observations above median:", length(control[which(control > median(control))])))
noquote(paste("Number of observations at median:", length(control[which(control == median(control))])))
```


\textbf{Truncated Plot}
```{r}
noquote(paste("Median:", median(truncated)))
noquote(paste("Number of observations below median:", length(truncated[which(truncated < median(truncated))])))
noquote(paste("Number of observations above median:", length(truncated[which(truncated > median(truncated))])))
noquote(paste("Number of observations at median:", length(truncated[which(truncated == median(truncated))])))
```
We now move on to consider the one-sample sign test. This has a significantly lower power than the t-test and WMW test, but is required as the data violates the conditions for these two tests.

We will first look at the two sided tests to decipher if the sample medians differ significantly from the true value of 42. \newline

\textbf{Two sided sign tests for the control plot responses}
```{r echo=F}
noquote(paste("*CONTROL*"))
SIGN.test(control, md=42, alternative="t")
```

\textbf{Two sided sign tests for the truncated plot responses}
```{r}
noquote(paste("*TRUNCATED*"))
SIGN.test(truncated, md=42, alternative="t")
```


The p values both being $<< 0.05$ signifies that the medians do in fact differ from the true value of 42. In fact we see that, for the control plot, the $95%$ confidence interval has both a lower and upper bound of 41, meaning we have a $95%$ chance that the true median of this population is 41. Similarly, the $95%$ confidence interval for the truncated plot is given as $[41, 41.25]$, meaning once again we have a $95%$ chance of the true median lying in this range. Thus we can infer that participants tended to slightly underestimate the height of this bar, no matter whether the axis was truncated or not. This makes sense as the top of the bar will appear to be at the same point on both scales. The underestimation may be as a result of the default scales going up to only 40; the respondents may have seen the bar being slightly above the 40 mark, and thus taken this as 41 rather than the true value of 42. Here this doesn't have a significant impact, but say the scale was in £ billions for example, then an underestimation of one is significant. It may then be important to specify the exact numerical values of the bars alongside the bars themselves in order for the interpretation to be accurate. This again could be used to either deliberately or accidentally mislead consumers, such as into believing a rival company may be doing worse than they actually are.

To confirm that it is in fact underestimation we are dealing with, we perform one-sided sign tests. \newline

\textbf{One-sided sign tests for the control plot responses}
```{r echo=F}
noquote(paste("*CONTROL*"))
SIGN.test(control, md=42, alternative="l")
SIGN.test(control, md=42, alternative="g")
```

\textbf{One-sided sign tests for the truncated plot responses}
```{r}
noquote(paste("*TRUNCATED*"))
SIGN.test(truncated, md=42, alternative="l")
SIGN.test(truncated, md=42, alternative="g")
```
From this series of tests we see p-values of $<< 0.05$ when considering the median as less than 42, and p-values of 1 when considering it as greater than 42. Thus, we can deduce that respondents tended to underestimate by a small but statistically significant margin.


We could also consider taking a set of samples from a normal distribution of mean and variance the same as our set of responses, and performing a t-test on the set of means of these samples. Below is the result of taking the means of 100 samples, each of size 100, and performing two sided t-tests on the set of means.
```{r}
noquote(paste("*CONTROL*"))
means <- rep(NA, 100)
for(i in 1:100){
  samp <- rnorm(100, mean=mean(control), sd=sd(control))
  means[i] <- mean(samp)
}
t.test(means, mu=42)

noquote(paste("*TRUNCATED*"))
means <- rep(NA, 100)
for(i in 1:100){
  samp <- rnorm(100, mean=mean(truncated), sd=sd(truncated))
  means[i] <- mean(samp)
}
t.test(means, mu=42)

```
This follows our previous testing in the conclusion that we differ from the true value of 42, and once again we can observe in the $95%$ CI as well as the very negative t statistics that there was a tendency to underestimate the height of the bar.


Now, we haven't yet considered the plot with logarithmic scaling. Looking back at the summary statistics we see wildly different values to the responses in relation to other two plots. As previously mentioned there are answers of '10^9' and '10^15'. Even discounting these two values, as seen below by setting these values to NA, there is a wide range in the responses, from 9 all the way up to 1000. Again, in some situations the responses that are orders of magnitude greater than the others could be considered outliers, but here they provide important insight. See below the summary statistics for the data after removing the two high magnitude values. 

```{r}
logarithmic <- log_y_scale$log_1
logarithmic[which(logarithmic == "Don't know")] <- NA
logarithmic[which(logarithmic == "Next to none.")] <- NA
logarithmic[which(logarithmic == "10^15")] <- NA
logarithmic[which(logarithmic == "10^9")] <-NA
logarithmic <- as.numeric(logarithmic)
noquote(paste('n = ', length(na.exclude(logarithmic))))
summary(na.exclude(logarithmic))
noquote(paste('Var =',var(logarithmic, na.rm=T)))
```

It seems that the mean is still much higher than the true value, at 67.07, and the IQR has stayed the same. Note that there is still a value of 1000 included in the data, which will be causing a skew to the right, and this again means there is a fairly large variance, this time of 28809.56. 

The below density plot shows the two curve from before, but with the curve of the logarithmic curve added. 

```{r echo=F, fig.cap = "Density plot showing distributions of responses regarding all three plots"}

logarithmic <- log_y_scale$log_1
logarithmic[which(logarithmic == "Don't know")] <- NA
logarithmic[which(logarithmic == "Next to none.")] <- NA
logarithmic[which(logarithmic == "10^15")] <- 10e+15
logarithmic[which(logarithmic == "10^9")] <- 10e+9
logarithmic <- as.numeric(logarithmic)


ggplot() +
  geom_density(data = as.data.frame(control), aes(x=control, col = "Control"))+  
  geom_density(data = as.data.frame(truncated), aes(x=truncated, col = "Truncated"))+
  geom_density(data = as.data.frame(logarithmic), aes(x=logarithmic, col = "Logarithmic"))+

  labs(x="Response", y="Density")+
  annotate("text", x=6e+15, y = 1.5, label="Approximately many times would you say the", size = 4)+
  annotate("text", x=6e+15, y = 1.4, label="'Salmon Ladder' was used?", size = 4)+
  annotate("text", x=6e+15, y = 1.3, label="Whole population, NAs excluded (n=67)", size = 3)+
  scale_colour_manual(breaks = brks, values = vals)+
  theme_classic()

```

This plot does not give us much information about the distribution of the responses for the logarithmically scaled plot due to the values with high magnitude causing the x-axis to extend beyond a point for which we can discern any meaningful distributions. Consider removing values $\geq 1000$ to look at the distribution of the lower values. Removing the four values $\geq 1000$ we obtain the following density plot;

```{r echo=F, fig.cap = "Density plot showing distributions of responses regarding all three plots, after removing values of greater or equal to 1000"}

logarithmic <- log_y_scale$log_1
logarithmic[which(logarithmic == "Don't know")] <- NA
logarithmic[which(logarithmic == "Next to none.")] <- NA
logarithmic[which(logarithmic == "10^15")] <- NA
logarithmic[which(logarithmic == "10^9")] <- NA
logarithmic[which(logarithmic == "1000.0")] <- NA
logarithmic[which(logarithmic == "1000")] <- NA
logarithmic <- as.numeric(logarithmic)


ggplot() +
  geom_density(data = as.data.frame(control), aes(x=control, col = "Control"))+  
  geom_density(data = as.data.frame(truncated), aes(x=truncated, col = "Truncated"))+
  geom_density(data = as.data.frame(logarithmic), aes(x=logarithmic, col = "Logarithmic"))+

  labs(x="Response", y="Density")+
  annotate("text", x=110, y = 0.63, label="Approximately many times would you say the", size = 4)+
  annotate("text", x=110, y = 0.6, label="'Salmon Ladder' was used?", size = 4)+
  annotate("text", x=110, y = 0.57, label="Without values >= 1000 (n=70)", size = 3)+
  scale_colour_manual(breaks = brks, values = vals)+
  theme_classic()

```
This gives a better idea of the distribution. we see that almost all of the density of the control and truncated plot is around the 40 mark, whereas the logarithmic has a much greater spread with much lower densities. This, again, could reflect confusion or less familiarity regarding this scaling. This should be considered when designing visualisations; the creator of the visualisations may find the logarithmic scale more effective in showing the data, but they should consider the target audience. Are the audience going to be familiar with this? If, for example, visualisations are being published in a paper targeted at academics in a subject likely to use such scalings often and understand them, this may be a good way to depict the data. However, using this in something such as an advertising campaign could mislead the public, causing them to either over or under estimate values. As previously discussed, however, this is often done deliberately in order to push the message the creator wishes to sell. 

While it at first glance appears that the logarithmic scale alone causes these drastic range of values, we must also consider the notation used. As mentioned prior, the default notation in Python for a logarithmic scale is standard form; in our case we have three tick values on the y-axis of 0, $10^0$ and $10^1$. To explore this, we can split the surveys by language to obtain two sets of data; one for R and one for Python. Now on closer inspection of the separate languages (below), the large range is almost fully attributed fully to the python versions of the plot. 

Consider first the summary statistics for the R version. 

\textbf{Summary statistics of the R versions}
```{r echo=F}

ctrl_y_scale_r <- rbind(r1[,c(4:7, 10:13)], r2[,c(4:7, 10:13)], r3[,c(4:7, 14:17)], r4[,c(4:7, 18:21)], r5[,c(4:7, 14:17)], r6[,c(4:7, 18:21)])
log_y_scale_r <- rbind(r1[,c(4:7, 14:17)], r2[,c(4:7, 18:21)], r3[,c(4:7, 10:13)], r4[,c(4:7, 10:13)], r5[,c(4:7, 18:21)], r6[,c(4:7, 14:17)])
trnc_y_scale_r <- rbind(r1[,c(4:7, 18:21)], r2[,c(4:7, 14:17)], r3[,c(4:7, 18:21)], r4[,c(4:7, 14:17)], r5[,c(4:7, 10:13)], r6[,c(4:7, 10:13)])

r_control <- ctrl_y_scale_r$con_1
r_control[15] <- 41.5 # take midpoint of two values
r_control <- as.numeric(r_control)

r_truncated <- as.numeric(trnc_y_scale_r$trn_1)

r_logarithmic <- log_y_scale_r$log_1

y_scale_r <- cbind(r_control, r_truncated, r_logarithmic)

noquote(paste("n = ", length(r_control)))
summary(y_scale_r)
```
We see that, based on the median and mean, the responses for log plot were on average lower than that of the control or truncated plots, conversely to the whole population in which the mean is magnitudes greater, although the median here is the same as for the whole population, with a slightly smaller interquartile range of size 5. We again see that the upper limit of the interquartile range is 40; below the true value. The whole range here is from 30 to 120, so does still show that there may be some large discrepancies between responses, however much less than the whole population.

Looking at the control plot now, the values seem very similar to those for the whole population. With a similar mean and identical median. The whole range is slightly smaller, but the interquartile range is the same as before, signifying that the spread in the centre of the data is the same, with slightly less spread towards the upper tail. This could potentially show a slightly better gauging of the value for the R plot than the Python, but we can also calculate that there is only one response higher than 43, which is the 45 at the upper end of the range for the Python population. We note that there is also only one value of 43; all other values are in the range $[40, 42]$. The values of 43 and 45 could possibly be considered as outliers, and then we see minimal differences in the distributions of the data for each of the languages. 

Similarly to the control plot, we see that the distribution for the Python version of the truncated plot has an almost identical distribution to the total population or R population.

Below see the density plot for the R data.

```{r echo=F}
ggplot() +
  geom_density(data = as.data.frame(r_control), aes(x=r_control, col = "Control"))+    
  geom_density(data = as.data.frame(r_truncated), aes(x=r_truncated, col = "Truncated"))+
  geom_density(data = as.data.frame(r_logarithmic), aes(x=r_logarithmic, col = "Logarithmic"))+

  
  labs(x="Response", y="Density")+
  annotate("text", x= 80, y = 0.67, label="Approximately many times would you", size = 4)+
  annotate("text", x= 80, y = 0.64, label="say the 'Salmon Ladder' was used?", size = 4)+
  annotate("text", x= 80, y = 0.61, label="R population (n=38)", size = 3)+
  scale_colour_manual(breaks = brks, values = vals)+
  theme_classic()

```

As expected, the distributions of the control and truncated plots so far look similar to the plots for the whole population. To get a clearer picture of the distributions we also plot these side-by-side without the log data.

```{r fig.height= 4, fig.width=9}
control <- ctrl_y_scale$con_1
control[which(control == "41/42")] <- 41.5 # take midpoint of two values
control <- as.numeric(control)
 
truncated <- as.numeric(trnc_y_scale$trn_1)

p <- ggplot() +
       geom_density(data = as.data.frame(control), aes(x=control, col = "Control"), show.legend = F)+
       geom_density(data = as.data.frame(truncated), aes(x=truncated, col = "Truncated"), show.legend = F)+
       labs(x="Response", y="Density")+
       annotate("text", x=43.5,   y = 0.66, label="Approximately many times would you say ", size = 3)+
       annotate("text", x=43.5, y = 0.62, label="the 'Salmon Ladder' was used?", size = 3)+
       annotate("text", x=43.5, y = 0.58, label="Whole population (n=70)", size = 3)+
       scale_colour_manual(breaks = brks[1:2], values = vals[1:2])+
       theme_classic()


q <- ggplot() +
       geom_density(data = as.data.frame(r_control), aes(x=r_control, col = "Control"), show.legend = F)+  
       geom_density(data = as.data.frame(r_truncated), aes(x=r_truncated, col = "Truncated"), show.legend = F)+
       labs(x="Response", y="Density")+
       annotate("text", x=43.5, y = 0.66, label="Approximately many times would you say ", size = 3)+
       annotate("text", x=43.5, y = 0.62, label="the 'Salmon Ladder' was used?", size = 3)+
       annotate("text", x=43.5, y = 0.58, label="R population (n=38)", size = 3)+
       scale_colour_manual(breaks = brks[1:2], values = vals[1:2])+
       theme_classic()

p_leg <- ggplot() +
       geom_density(data = as.data.frame(r_control), aes(x=r_control, col = "Control"))+  
       geom_density(data = as.data.frame(r_truncated), aes(x=r_truncated, col = "Truncated"))+
       scale_colour_manual(breaks = brks[1:2], values = vals[1:2])+
       theme_classic()

extract_legend <- function(my_ggp) {
  step1 <- ggplot_gtable(ggplot_build(my_ggp))
  step2 <- which(sapply(step1$grobs, function(x) x$name) == "guide-box")
  step3 <- step1$grobs[[step2]]
  return(step3)
}

shared_legend <- extract_legend(p_leg)

grid.arrange(arrangeGrob(p, q, ncol = 2), shared_legend, nrow = 1, widths = c(8, 1))
```

We can in fact see that the distributions of each population are fairly similarly shaped. However, the two curves on the R density plot appear to differ from each other slightly more than on the density plot for the whole population, and the second peak is higher, with greater density at 42 than the whole population, signifying a higher proportion of the values lying around this point than in the total population. we also see that the peak for the control plot are slightly higher than the truncated plot, signifying that there are perhaps more responses around the 41/42 mark than for the truncated plot, which makes sense as we also see the right tail of the truncated plot curve lifts slightly as a result of the 43 value. Overall it doesn't look like the responses for the control and truncated plots for the R population differ much from the overall population.

Now consider the two density curves for the responses relating to the logarithmically scaled plot.

```{r fig.height= 4, fig.width=9}

logarithmic <- log_y_scale$log_1
logarithmic[which(logarithmic == "Don't know")] <- NA
logarithmic[which(logarithmic == "Next to none.")] <- NA
logarithmic <- as.numeric(logarithmic)

p <- ggplot() +
       geom_density(data = as.data.frame(logarithmic), aes(x=logarithmic, col = "Logarithmic"), show.legend = F)+
       labs(x="Response", y="Density")+
       annotate("text", x=90, y = 0.044, label="Approximately many times would you say ", size = 4)+
       annotate("text", x=90, y = 0.042, label="the 'Salmon Ladder' was used?", size = 4)+
       annotate("text", x=90, y = 0.04, label="Whole population (n=70)", size = 4)+
       scale_colour_manual(breaks = brks[3], values = vals[3])+
       scale_x_continuous(breaks=seq(20, 140, 20), labels = seq(20, 140, 20))+
       theme_classic()


q <- ggplot() +
       geom_density(data = as.data.frame(r_logarithmic), aes(x=r_logarithmic, col = "Logarithmic"), show.legend = F)+  
       labs(x="Response", y="Density")+
       annotate("text", x=80, y = 0.11, label="Approximately many times would you say ", size = 4)+
       annotate("text", x=80, y = 0.105, label="the 'Salmon Ladder' was used?", size = 4)+
       annotate("text", x=80, y = 0.10, label="R population (n=38)", size = 4)+
       scale_colour_manual(breaks = brks[3], values = vals[3])+
       scale_x_continuous(breaks=seq(30, 120, 10), labels = seq(30, 120, 10))+
       theme_classic()

p_leg <- ggplot() +
       geom_density(data = as.data.frame(r_logarithmic), aes(x=r_logarithmic, col = "Logarithmic"))+  
       scale_colour_manual(breaks = brks[3], values = vals[3])+
       theme_classic()

extract_legend <- function(my_ggp) {
  step1 <- ggplot_gtable(ggplot_build(my_ggp))
  step2 <- which(sapply(step1$grobs, function(x) x$name) == "guide-box")
  step3 <- step1$grobs[[step2]]
  return(step3)
}

shared_legend <- extract_legend(p_leg)

grid.arrange(arrangeGrob(p, q, ncol = 2), shared_legend, nrow = 1, widths = c(8, 1))
```

Once again, we see the plot for the whole population, which we discussed before as showing little information about the lower end of the distribution. The density plot for the R population shows the spread up to 120. It appears that the majority of the density lies over the range $[30, 50]$, with a peak around the 35 mark. This signifies the underestimation of values using the logarithmic plot as compared to the other two. For the R version, any differences can be fully attributed to the scale itself, unlike for the Python plot whereby familiarity with standard form notation has an impact. It was hypothesised prior to performing the survey that there may be underestimations as looking at the value of 30 on the axis and comparing it with the top of the bar, it appears the bar falls just above 30.

Now look at the same density plots when removing values $\geq 1000$.

```{r fig.height= 4, fig.width=9}

logarithmic <- log_y_scale$log_1
logarithmic[which(logarithmic == "Don't know")] <- NA
logarithmic[which(logarithmic == "Next to none.")] <- NA
logarithmic[which(logarithmic == "10^15")] <- NA
logarithmic[which(logarithmic == "10^9")] <- NA
logarithmic[which(logarithmic == "1000.0")] <- NA
logarithmic[which(logarithmic == "1000")] <- NA
logarithmic <- as.numeric(logarithmic)

p <- ggplot() +
       geom_density(data = as.data.frame(logarithmic), aes(x=logarithmic, col = "Logarithmic"), show.legend = F)+
       labs(x="Response", y="Density")+
       annotate("text", x=90, y = 0.044, label="Approximately many times would you say ", size = 4)+
       annotate("text", x=90, y = 0.042, label="the 'Salmon Ladder' was used?", size = 4)+
       annotate("text", x=90, y = 0.04, label="Whole population (n=70)", size = 4)+
       scale_colour_manual(breaks = brks[3], values = vals[3])+
      scale_x_continuous(breaks=seq(20, 140, 20), labels = seq(20, 140, 20))+
       theme_classic()


q <- ggplot() +
       geom_density(data = as.data.frame(r_logarithmic), aes(x=r_logarithmic, col = "Logarithmic"), show.legend = F)+  
       labs(x="Response", y="Density")+
       annotate("text", x=80, y = 0.11, label="Approximately many times would you say ", size = 4)+
       annotate("text", x=80, y = 0.105, label="the 'Salmon Ladder' was used?", size = 4)+
       annotate("text", x=80, y = 0.10, label="R population (n=38)", size = 4)+
       scale_colour_manual(breaks = brks[3], values = vals[3])+
       scale_x_continuous(breaks=seq(30, 120, 10), labels = seq(30, 120, 10))+
       theme_classic()

p_leg <- ggplot() +
       geom_density(data = as.data.frame(r_logarithmic), aes(x=r_logarithmic, col = "Logarithmic"))+  
       scale_colour_manual(breaks = brks[3], values = vals[3])+
       theme_classic()

extract_legend <- function(my_ggp) {
  step1 <- ggplot_gtable(ggplot_build(my_ggp))
  step2 <- which(sapply(step1$grobs, function(x) x$name) == "guide-box")
  step3 <- step1$grobs[[step2]]
  return(step3)
}

shared_legend <- extract_legend(p_leg)

grid.arrange(arrangeGrob(p, q, ncol = 2), shared_legend, nrow = 1, widths = c(8, 1))
```
We see for the whole population a peak at 40 with drops to a tail at around 60, with a very small density after this point. This follows the R population, where the majority of density is below 60. 

Now we consider the same for the responses corresponding to the Python visualisations.

\textbf{Summary statistics of the Python versions}
```{r echo=F}

ctrl_y_scale_py <- rbind(py1[,c(4:7, 10:13)], py2[,c(4:7, 10:13)], py3[,c(4:7, 14:17)], py4[,c(4:7, 18:21)], py5[,c(4:7, 14:17)], py6[,c(4:7, 18:21)])
log_y_scale_py <- rbind(py1[,c(4:7, 14:17)], py2[,c(4:7, 18:21)], py3[,c(4:7, 10:13)], py4[,c(4:7, 10:13)], py5[,c(4:7, 18:21)], py6[,c(4:7, 14:17)])
trnc_y_scale_py <- rbind(py1[,c(4:7, 18:21)], py2[,c(4:7, 14:17)], py3[,c(4:7, 18:21)], py4[,c(4:7, 14:17)], py5[,c(4:7, 10:13)], py6[,c(4:7, 10:13)])

py_control <- ctrl_y_scale_py$con_1

py_truncated <- as.numeric(trnc_y_scale_py$trn_1)

py_logarithmic <- log_y_scale_py$log_1
py_logarithmic[which(py_logarithmic == "Don't know")] <- NA
py_logarithmic[which(py_logarithmic == "Next to none.")] <- NA
py_logarithmic[which(py_logarithmic == "10^15")] <- 1e+15
py_logarithmic[which(py_logarithmic == "10^9")] <- 1e+9
py_logarithmic <- na.exclude(as.numeric(py_logarithmic))


y_scale_py <- cbind(py_control, py_truncated, py_logarithmic)
noquote(paste('n (control) = ', length(py_control)))
noquote(paste('n (truncated) = ', length(py_truncated)))
noquote(paste('n (logarithmic) = ', length(py_logarithmic)))
summary(y_scale_py)
```

The statistics for the control and truncated plots again appear to centre around 41, based on the median and mean values as well as the IQR. The range for the truncated plot responses is slightly smaller than that of the overall population, at size 4 rather than 5. These results are consistent with the statistics for the prior analysed populations, whereby there appears to be a slight underestimation in gauging the height of the bar. This perhaps depicts that the plotting package defaults don't significantly affect interpretation when considering these two scales.

As expected, the statistics for responses corresponding to the logarithmic plot are much different than those of the R population. Looking at the data set as a whole, we can again see that the values contributing heavily to the large mean were the two given as 10^15 and 10^9, alongside two responses of 1000. This lends to the idea that using matplotlib's default of standard form notation for log scales may have misled some participants who perhaps are less familiar with standard form. Adding to this conclusion are the invalid text responses, "Don't know" and "Next to None.", which show that there was confusion regarding the height of the bar.

The density plot below for the control and truncated responses looks very different to those for the whole population and R population. We see significant differences between the control and truncated density curves, as well as between this plot and the previously discussed density plots. 
```{r echo=F}
ggplot() +
  geom_density(data = as.data.frame(py_control), aes(x=py_control, col = "Control"))+  
  #geom_density(data = as.data.frame(py_logarithmic), aes(x=py_logarithmic, col = "Logarithmic"))+
  geom_density(data = as.data.frame(py_truncated), aes(x=py_truncated, col = "Truncated"))+
  

  labs(x="Response", y="Density")+
  annotate("text", x=44, y = 2.2, label="Approximately many times would you say the", size = 4)+
  annotate("text", x=44, y = 2.1, label="'Salmon Ladder' was used?", size = 4)+
  annotate("text", x=44, y = 2, label="Python popualtion (n=31, NAs excluded )", size = 3)+
  scale_colour_manual(breaks = brks, values = vals)+
  theme_classic()

```
the control plot curve appears smoother than that of the whole and R populations, whereas the curve for the truncated plot responses is much less smooth with much more variability, despite the summary statistics seeming relatively similar for both. Both curves once again reach a maximum density at 41 with a large amount of the density falling below 43.

Once again, we now consider the density plot of the responses to the logarithmic plot, where we have once again excluded the values $\geq$ 1000.

```{r echo=F}

py_logarithmic <- log_y_scale_py$log_1
py_logarithmic[which(py_logarithmic == "Don't know")] <- NA
py_logarithmic[which(py_logarithmic == "Next to none.")] <- NA
py_logarithmic[which(py_logarithmic == "10^15")] <- NA
py_logarithmic[which(py_logarithmic == "10^9")] <- NA
py_logarithmic[which(py_logarithmic == "1000")] <- NA
py_logarithmic[which(py_logarithmic == "1000.0")] <- NA

py_logarithmic <- as.numeric(py_logarithmic)


ggplot() +
  geom_density(data = as.data.frame(py_logarithmic), aes(x=py_logarithmic, col = "Logarithmic"))+
  labs(x="Response", y="Density")+
  #annotate("text", x=5e+14, y = 1.5, label="Approximately many times would you say the", size = 4)+
  #annotate("text", x=5e+14, y = 1.4, label="'Salmon Ladder' was used?", size = 4)+
  #annotate("text", x=5e+14, y = 1.3, label="Whole population (n=70)", size = 3)+
  scale_colour_manual(breaks = brks[3], values = vals[3])+
  scale_x_continuous(limits = c(0, 120), breaks=seq(0, 160, 20), labels = seq(0, 160, 20))+
  theme_classic()

```
There appears to be a high density peak around 20, which then gradually decreases as we tend towards 120. Although, this peak is large only relative the rest of this plot as opposed to the density curves of the control and truncated curves, where we have maximum densities of around 2.5 and 0.6 respectively. 
Overall, it appears that the use of the truncated scale had little impact on judging the height of an individual bar as compared to a control with no scale alterations, and these observations are consistent through both R and Python-created visualisations. It has also been observed that the scale by default ending at 40 while the bar height is at 42 leads to some underestimation in the height for both the control and truncated bar plots.

The log scale, when using R's default of non-standard form notation, also leads to underestimation of values and to a greater level than the other two scales, suggesting this scale itself has an impact on interpreting the height of an individual bar, potentially as a result of seeing the value of 30 on the axis and subconsciously extrapolating this in a linear manner, and thus misjudging the actual position of the bar when seeing it appears just higher than 30. However, we do still have some high values in this set, which again could be down to extrapolation errors. The python default of standard form notation appears to have confused certain respondents, who are perhaps not as used to seeing this notation, and there was a very large range in the responses along with one person not even entering a number, but rather stating that they "Don't know", and another stating they believed the value was "Next to none". The "Nest to none" entry is very subjective, but could potentially be be assumed as a value close to 0, once again maybe as a result of standard form being less well known.

**Approximately how much more than 'Log Grip' would you say 'Salmon Ladder' was was used?**

Now we consider the results from the second question, in which the participants were asked to respond on a scale from 1-7. The density plot below depicts the distribution of results for each of the three plot types. We see that the distributions appear to once again be non-normal.


```{r echo=F}

control <- ctrl_y_scale$con_2
truncated <- trnc_y_scale$trn_2
logarithmic <- log_y_scale$log_2

y_scale_2_all <- cbind(control, truncated, logarithmic)

ggplot() +
  geom_density(data = as.data.frame(control), aes(x=control, col = "Control"))+
  geom_density(data = as.data.frame(truncated), aes(x=truncated, col = "Truncated"))+ 
  geom_density(data = as.data.frame(logarithmic), aes(x=logarithmic, col = "Logarithmic"))+
  
  annotate("text", x=4, y = 0.5, label="Approximately how much more than 'Log Grip'", size = 4)+
  annotate("text", x=4, y = 0.47, label="would you say 'Salmon Ladder' was used?", size = 4)+
  annotate("text", x=4, y = 0.44, label="Whole population (n=70)", size = 3)+
  scale_colour_manual(breaks = brks, values = vals)+
  labs(x="Response", y="Density")+
  
  theme_classic()

```
The distribution for the logarithmic plot values has a fairly wide, flat curve, showing that the subjective view appeared to vary a fair amount from respondent to respondent. The distribution for the truncated plot seems very skewed to the right, depicting that the subjective view on the difference between the bar heights was that the difference was on the larger side. 

```{r echo=F}
noquote(paste('n (control) = ', length(control)))
noquote(paste('n (truncated) = ', length(truncated)))
noquote(paste('n (logarithmic) = ', length(logarithmic)))
noquote(rbind(summary(y_scale_2_all), c(paste0('Var    :', round(var(control), 3)), paste0('Var    :', round(var(truncated), 3)), paste0('Var    :', round(var(logarithmic), 3)))))
```
An initial look at the table of summary statistics reveal means of 5.375, 3.671 and 5.871 respectively for the control, log and truncated plots, meaning that for the 'baseline' control plot participants, on average, judged the difference to be moderately significant, with the perceived difference being smaller for the log plot and marginally larger for the truncated plot. This appears to be consistent with results from [[[CITE chrome-extension://cbnaodkpfinfiipjblikofhlhlcickei/src/pdfviewer/web/viewer.html?file=file:///C:/Users/Katie/Downloads/YangVargasRestrepoStanleyMarsh%20(2020).pdf]]], in which the researchers, similar to this survey, showed participants a series of control bar plots alongside those with a truncated axis, and concluded that the difference in values for the truncated axis were perceived to be larger than those of the control plots. However, the average perceived difference here is fairly small, much smaller than initially hypothesised, so tests will be needed to decipher whether this is significant.
The logarithmic plot causing the average perceived difference to be smaller follows the hypothesis from prior to running the survey. 

The box plot shows these results for each plot type.

```{r echo=F}
y_scale_2_all <- as.data.frame(y_scale_2_all)
resp <- c(control, truncated, logarithmic)
type <- c(rep('Control', 70), rep('Truncated', 70), rep('Logarithmic', 70)) 
stats_2 <- data.frame(resp, type)

ggplot(data = stats_2, aes(x=type, y=resp, fill=type))+
geom_boxplot(outlier.colour="black", outlier.shape=1,
             outlier.size=2, notch=F)+
  theme_classic()+
  stat_summary(fun=mean, geom="point", shape=15, size=4)+
  scale_fill_manual(breaks = brks, values = vals)+
  scale_y_continuous(labels = seq(1, 7, 1), breaks = seq(1, 7, 1))+
  ylab("Value")+
  xlab("Plot Type")
```
We see that the interquartile range for the control plot is smallest of the three at 1.75, followed by the truncated plot at 2, and then the log plot at 2.75. This depicts that overall, there was more of a consensus in the subjective perception of the difference for the control plot than the other two, and less agreement between participants for the logarithmic scale. 

The black squares represent the means here, and we can see that for the control and truncated boxes, the mean is higher than the median, perhaps signifying a positive skew, with a slightly negative skew for the logarithmic plot. 


The summary statistics for the R population are given below.

```{r}
control_r <- ctrl_y_scale_r$con_2
truncated_r <- trnc_y_scale_r$trn_2
logarithmic_r <- log_y_scale_r$log_2

y_scale_2_r <- cbind(control_r, truncated_r, logarithmic_r)

ggplot() +
  geom_density(data = as.data.frame(control_r), aes(x=control_r, col = "Control"))+
  geom_density(data = as.data.frame(truncated_r), aes(x=truncated_r, col = "Truncated"))+ 
  geom_density(data = as.data.frame(logarithmic_r), aes(x=logarithmic_r, col = "Logarithmic"))+
  
  annotate("text", x=4, y = 0.5, label="Approximately how much more than 'Log Grip'", size = 4)+
  annotate("text", x=4, y = 0.47, label="would you say 'Salmon Ladder' was used?", size = 4)+
  annotate("text", x=4, y = 0.44, label="Whole population (n=70)", size = 3)+
  scale_colour_manual(breaks = brks, values = vals)+
  labs(x="Response", y="Density")+
  
  theme_classic()


noquote(paste('n (control) = ', length(control_r)))
noquote(paste('n (truncated) = ', length(truncated_r)))
noquote(paste('n (logarithmic) = ', length(logarithmic_r)))

noquote(rbind(summary(y_scale_2_r), c(paste0('Var    :', round(var(control_r), 3)), paste0('Var    :', round(var(truncated_r), 3)), paste0('Var    :', round(var(logarithmic_r), 3)))))
```

The means of the R population are very similar to the whole population for the control and truncated plots, with the mean for the logarithmic plot is slightly higher. The control and truncated values lie on the upper half of the scale, depicting that the difference in heights between the two bars was perceived to be considerable. The mean for the logarithmic responses is 4.243; almost directly in the centre of the scale. Thus, this difference was considered moderate but not too considerable. The medians for both the control and truncated plots are 6, with the median of the logarithmic slightly lower at 5, showing that these data centre around 6 and 5 respectively. All of these do, however, have large ranges, with the truncated and logarithmic responses having a range over the whole scale of $[1, 7]$ and the control with a range over $[3, 7]$. We therefore had some respondents who felt the differences between bar heights were very small, although the IQRs of the three, in order, are $[5, 6]$, $[5, 7]$ and $[3, 5.75]$ respectively, showing that 50% of the responses lie fairly close to the means, and the IQRs for the control and truncated plot responses encompass values in the upper half of the scale, furthering the conclusion that these height differences were perceived to be larger. 


```{r echo=F}
y_scale_2_r <- as.data.frame(y_scale_2_r)
resp <- c(control_r, truncated_r, logarithmic_r)
type <- c(rep('Control', 38), rep('Truncated', 38), rep('Logarithmic', 38)) 
stats_2 <- data.frame(resp, type)

ggplot(data = stats_2, aes(x=type, y=resp, fill=type))+
geom_boxplot(outlier.colour="black", outlier.shape=1,
             outlier.size=2, notch=F)+
  theme_classic()+
  stat_summary(fun=mean, geom="point", shape=15, size=4)+
  scale_fill_manual(breaks = brks, values = vals)+
  scale_y_continuous(labels = seq(1, 7, 1), breaks = seq(1, 7, 1))+
  ylab("Value")+
  xlab("Plot Type")
```
The control plot has the smallest IQR, with the value of 3 picked up as an outlier. The boxes for the log and truncated responses, as expected, sit slightly below and above the control box, respectively. Although, we also see that the upper end of the IQR for the log responses almost matches that of the control responses, and the lower end of the IQR for the truncated responses matches the lower end of the control plot. This shows that all three had a number of responses in the range $[5, 6]$, but the logarithmic responses also contained a fair amount of responses below this, and the truncated responses contained a fair amount above the $[5, 6]$ range. It can also be seen that the value of 1 is picked up as an outlier for the truncated responses, although not for the logarithmic responses. Thus it appears that 1 is in fact a response that can be considered as a valid response. It can also be noted that the boxplot of the logarithmic responses covers the whole range $[1, 7]$ with no outliers, implying that there was a large amount of variability in responses between participants. This is also highlighted in the summary statistics, where we have a variance of 2.523, which is higher than for the control and truncated.


```{r}
control_py <- ctrl_y_scale_py$con_2
truncated_py <- trnc_y_scale_py$trn_2
logarithmic_py <- log_y_scale_py$log_2

y_scale_2_py <- cbind(control_py, truncated_py, logarithmic_py)

ggplot() +
  geom_density(data = as.data.frame(control_py), aes(x=control_py, col = "Control"))+
  geom_density(data = as.data.frame(truncated_py), aes(x=truncated_py, col = "Truncated"))+ 
  geom_density(data = as.data.frame(logarithmic_py), aes(x=logarithmic_py, col = "Logarithmic"))+
  
  annotate("text", x=4, y = 0.5, label="Approximately how much more than 'Log Grip'", size = 4)+
  annotate("text", x=4, y = 0.47, label="would you say 'Salmon Ladder' was used?", size = 4)+
  annotate("text", x=4, y = 0.44, label="Whole population (n=70)", size = 3)+
  scale_colour_manual(breaks = brks, values = vals)+
  labs(x="Response", y="Density")+
  
  theme_classic()

noquote(paste('n (control) = ', length(control_py)))
noquote(paste('n (truncated) = ', length(truncated_py)))
noquote(paste('n (logarithmic) = ', length(logarithmic_py)))

noquote(rbind(summary(y_scale_2_py), c(paste0('Var    :', round(var(control_py), 3)), paste0('Var    :', round(var(truncated_py), 3)), paste0('Var    :', round(var(logarithmic_py), 3)))))
```
The statistics for the control and truncated plots are once again similar to those of the whole population and the R population, with the mean of the logarithmic responses slightly lower again at 2.968, signifying that the difference between the bar heights was perceived as very minimal. The IQR for the control responses place the bulk of these values in the range $[4, 6]$, which tells us that, on average, respondents felt the height difference was moderate. The truncated plot responses IQR places these values in the range $[5.5, 7]$, showing a larger perceived difference, and conversely the perceived differences in the log scaled plot appear on the smaller side, given the IQR of $[2, 4]$.


```{r echo=F}
y_scale_2_py <- as.data.frame(y_scale_2_py)
resp <- c(control_py, truncated_py, logarithmic_py)
type <- c(rep('Control', 31), rep('Truncated', 31), rep('Logarithmic', 31)) 
stats_2 <- data.frame(resp, type)

ggplot(data = stats_2, aes(x=type, y=resp, fill=type))+
geom_boxplot(outlier.colour="black", outlier.shape=1,
             outlier.size=2, notch=F)+
  theme_classic()+
  stat_summary(fun=mean, geom="point", shape=15, size=4)+
  scale_fill_manual(breaks = brks, values = vals)+
  scale_y_continuous(labels = seq(1, 7, 1), breaks = seq(1, 7, 1))+
  ylab("Value")+
  xlab("Plot Type")
```
The box plots for the python population are much more distinct than for the R population, with little crossover of boxes. The log responses box is very obviously sat below the control, and the truncated lies above. The lower values of 1 and 2 are counted as outliers here for the truncated plot, although the boxplot for the log responses once again spreads over the whole range, but the box itself is shorter than that of the R population.

**Approximately how much more than 'Quintuple Steps' would you say 'Salmon Ladder' was used?**

This is a similar question to the one prior, but the purpose was to see if there was a difference in perceived difference for bars next to each other vs bars on opposite sides of the plot.


```{r echo=F}
control <- ctrl_y_scale$con_3
truncated <- trnc_y_scale$trn_3
logarithmic <- log_y_scale$log_3

y_scale_3_all <- cbind(control, logarithmic, truncated)

ggplot() +
  geom_density(data = as.data.frame(control), aes(x=control, col = "Control"))+
  geom_density(data = as.data.frame(logarithmic), aes(x=logarithmic, col = "Logarithmic"))+
  geom_density(data = as.data.frame(truncated), aes(x=truncated, col = "Truncated"))+
  annotate("text", x=4, y = 0.5, label="Approximately how much more than 'Quintuple Steps'", size = 4)+
  annotate("text", x=4, y = 0.47, label="would you say 'Salmon Ladder' was used?", size = 4)+
  labs(x="Response", y="Density")+
  scale_colour_manual(breaks = brks, values = vals)+
  theme_classic()
```

```{r, echo=F}
summary(y_scale_3_all)
```

```{r, echo=F}
y_scale_3_all <- as.data.frame(y_scale_3_all)
resp <- c(y_scale_3_all$control, y_scale_3_all$logarithmic, y_scale_3_all$truncated)
type <- c(rep('Control', 70), rep('Truncated', 70), rep('Logarithmic', 70)) 
stats_3 <- data.frame(resp, type)

ggplot(data = stats_3, aes(x=type, y=resp, fill=type))+
geom_boxplot(outlier.colour="black", outlier.shape=1,
             outlier.size=2, notch=F)+
  theme_classic()+
  stat_summary(fun=mean, geom="point", shape=15, size=4)+
  scale_fill_manual(breaks = brks, values = vals)+
  scale_y_continuous(labels = seq(1, 7, 1), breaks = seq(1, 7, 1))+
  ylab("Value")+
  xlab("Plot Type")

```

**In your opinion, approximately how many times would you say 'Log Grip' was used, as a percentage of the number of times 'Salmon Ladder' was used?**
```{r echo=F}
con_4_all <- ctrl_y_scale$con_4
con_4_all[which(con_4_all == '12.5 %')] <- 12.5
con_4_all <- as.numeric(con_4_all)
for(i in 1:length(con_4_all)){
    if(con_4_all[i] < 1 && is.na(con_4_all[i])==FALSE){
       con_4_all[i] <- con_4_all[i]*100
    }
}


trn_4_all <- trnc_y_scale$trn_4
for(i in 1:length(trn_4_all)){
    if(trn_4_all[i] < 1 && is.na(trn_4_all[i])==FALSE){
       trn_4_all[i] <- trn_4_all[i]*100
    }
}

log_4_all <- log_y_scale$log_4
log_4_all[which(log_4_all == '3 %')] <- 3
log_4_all <- as.numeric(log_4_all)

for(i in 1:length(log_4_all)){
    if(log_4_all[i] < 1 && is.na(log_4_all[i])==FALSE){
       log_4_all[i] <- log_4_all[i]*100
    }
}

y_scale_4_all <- cbind(con_4_all, log_4_all, trn_4_all)
summary(y_scale_4_all)


```

```{r echo=F}

ggplot() +
  geom_density(data = as.data.frame(con_4_all), aes(x=con_4_all, col = "Control"))+
  geom_density(data = as.data.frame(trn_4_all), aes(x=trn_4_all, col = "Truncated"))+ 
  geom_density(data = as.data.frame(log_4_all), aes(x=log_4_all, col = "Log"))+
  
  annotate("text", x=52, y = 0.089, label="In your opinion, approximately how many times would you say ", size = 3)+
  annotate("text", x=52, y = 0.084, label="'Log Grip' was used, as a percentage of the number of times", size = 3)+
  annotate("text", x=52, y = 0.08, label="'Salmon Ladder' was used?", size = 3)+
  annotate("text", x=52, y = 0.075, label="Whole population (n=70)", size = 3)+
  
  labs(x="Response", y="Density")+
  scale_colour_brewer(palette="Dark2", labels = c('Control', 'Truncated', 'Log'))+
  theme_classic()

```
#### NAs
```{r echo=F}
index <- which(is.na(log_4_all))
cbind(index, y_scale_4_all[which(is.na(log_4_all)),])

rbind(ver1[4:9], ver2[4:9], ver3[4:9], ver4[4:9], ver5[4:9], ver6[4:9])[index,]
```


```{r, echo=F}
y_scale_4_all <- as.data.frame(na.exclude(y_scale_4_all))

vals <- c(y_scale_4_all$con_4_all, y_scale_4_all$log_4_all, y_scale_4_all$trn_4_all)
type <- c(rep('Control', 66), rep('Log', 66), rep('Truncated', 66)) 
stats_4 <- data.frame(vals, type)

ggplot(data = stats_4, aes(x=type, y=vals, fill=type))+
geom_boxplot(outlier.colour="black", outlier.shape=1,
             outlier.size=2, notch=F)+
  theme_classic()+
  stat_summary(fun=mean, geom="point", shape=15, size=4)+
  scale_colour_manual(breaks = brks, values = vals)+
  scale_y_continuous()+
  ylab("Value")+
  xlab("Plot Type")

```

\subsection{Ninja Warrior - Part 2}

The second section of the survey tests whether altering aspect ratio of plots affects interpretation. The purpose of this is to mirror what my occur when visualisations are published, and may be resized to fit the section of the page they sit on. As in [[[CITE: http://perceptualedge.com/articles/visual_business_intelligence/bar_widths.pdf]]], it was hypothesised prior to the survey that an aspect ratio that narrows the bars may cause overestimation in values, and vice versa, using a ratio that widens bars could lead to underestimation. In the paper, the author discusses how increasing the widths of bars could distract from the bar height as well as take up excessive space on a page. It is also mentioned that wider bars may be "aesthetically displeasing". This section tests both how bar width alters perceived difference between bars as well as opinions on the aesthetics. The method in the paper also involves altering spaces between bars, including bar plots with spaces at 50% of the bar widths and then reducing the width of the space by a third. Conversely to this, we will not be considering different width of spaces between bars, but only the widths of the bars themselves. The author concludes that a length-to-width ratio of 10:1 appears to suffer from perceptual imbalance, but increasing this such that the bars become narrower and longer does not appear to have as much of an impact; the ratio can be increased relatively far with out causing much perceptual imbalance. In our version of this investigation, we have three bar plots of 7 obstacles, each with a different aspect ratio. The control, or default, plot is given as the plot for which the aspect ratio has not been altered, the plot with narrow bars has a doubled aspect ratio, and the plot wide bars a halved aspect ratio.


**How large would you say the difference between 'Jumping spider' and 'Salmon Ladder' is?**
This question once again uses the 7-point scale to gain a subjective view on the degree to which respondents felt the heights between the two bars corresponding to 'Jumping Spider' and 'Salmon Ladder' differed for three bar plots of 7 obstacles, where 'Salmon Ladder' is furthest to the left, and 'Jumping Spider' furthest to the right. 

```{r echo=F}
default <- def_ratio$def_1
narrower <- nar_ratio$nar_1
wider <- wid_ratio$wid_1
ratio_1_all <- cbind(default, wider, narrower)


noquote(paste('n (default) = ', length(default)))
noquote(paste('n (narrower) = ', length(narrower)))
noquote(paste('n (wider) = ', length(wider)))
noquote(rbind(summary(ratio_1_all), c(paste0('Var    :', round(var(default), 3)), paste0('Var    :', round(var(wider), 3)), paste0('Var    :', round(var(narrower), 3)))))

```
Looking at the means and medians here, it doesn't seem like there is that much of a difference in perception of the differences between the three aspect ratios. If anything, based on the means, we could say that the wider plot gave a slightly smaller perception of the difference, and the narrower plot slightly larger. However, these differences appear very marginal, although they do agree with the hypothesis formed from [[[CITE AS ABOVE]]].

To discuss the ranges, see the box plot below.

```{r, echo=F}

brks <- c("Default", "Wider", "Narrower")
vals <- c("#1c9e77", "#d95f02", "#7570b3")

ratio_1_all <- as.data.frame(ratio_1_all)
resp <- c(default, wider, narrower)
type <- c(rep('Default', 70), rep('Wider', 70), rep('Narrower', 70)) 
stats <- data.frame(resp, type)

ggplot(data = stats, aes(x=type, y=resp, fill=type))+
  geom_boxplot(outlier.colour="black", outlier.shape=1,
             outlier.size=2, notch=F)+
  theme_classic()+
  stat_summary(fun=mean, geom="point", shape=15, size=4)+
  scale_fill_manual(breaks = brks, values = vals)+
  scale_y_continuous(labels = seq(1, 7, 1), breaks = seq(1, 7, 1))+
  ylab("Value")+
  xlab("Plot Type")

```
From these box plots, it appears that the IQRs for the two plots with altered aspect ratios have very little, if any, overlap, despite the means being similar and medians being identical. The narrower plot shows a tendency for the responses to lie more towards the upper end of the scale than the wider plot, which also ranges over the upper half of the scale but between roughly 5 and 6 rather than 6 and 7. The default plot covers the entire IQR of both of the other plots, and the box plots then show that, even though the means and medians are very similar, the center bulk of the values for the narrower plot tended to be more towards the upper end of the default's IQR, whereas the central points of the wider plot sat on the lower half of this IQR. Additionally, we see that there are two outliers each for the narrower and wider plots, with values 2, 3 and 4. Perhaps excluding these from the data and re-checking the summary statistics we will see a more marked difference.



```{r echo=F}
default <- def_ratio$def_1

narrower <- nar_ratio$nar_1[which(nar_ratio$nar_1 != 3)]
narrower <- narrower[which(narrower != 4)]

wider <- wid_ratio$wid_1[which(wid_ratio$wid_1 != 2)]
wider <- wider[which(wider != 3)]

ratio_1_all <- cbind(default, wider, narrower)


noquote(paste('n (default) = ', length(default)))
noquote(paste('n (narrower) = ', length(narrower)))
noquote(paste('n (wider) = ', length(wider)))
noquote(rbind(summary(ratio_1_all), c(paste0('Var    :', round(var(default), 3)), paste0('Var    :', round(var(wider), 3)), paste0('Var    :', round(var(narrower), 3)))))

```

It seems that removing these outliers didn't actually have a huge effect on the means and medians, although as expected, the ranges and variances are lower, meaning the spread over values over the range is smaller, however this only furthers the point that altering the axis ratio appears to have minimal effect.This is again confirmed by looking at the distributions of the three plot types, which are very similar to one another. We can however see that the plot with the density for the wider plot is highest of the three for the values of 4 and 5, but is the lowest of the three for upper end of the distributions, and vice versa for the densities narrower plot. The default mostly stays in between the other two curves. For a third time, this gives way to the observation that the wider bars have a small lessening effect on gauging differences in height, and using narrower bars has a mild increasing effect on difference perception.

```{r echo=F}

ggplot() +
  geom_density(data = as.data.frame(default ), aes(x=default , col = "Default"))+
  geom_density(data = as.data.frame(wider   ), aes(x=wider   , col = "Wider"))+
  geom_density(data = as.data.frame(narrower), aes(x=narrower, col = "Narrower"))+
  labs(x="Response", y="Density")+
  annotate("text", x = 5, y = 0.63, label = "How large would you say the difference between") +
  annotate("text", x = 5, y = 0.6, label = "'Jumping spider' and 'Salmon Ladder' is?") +
  annotate("text", x = 5, y = 0.55, label = "Whole popualation") +
  scale_colour_manual(breaks = brks, values = vals)+
  theme_classic()

```


**How large would you say the difference between 'Log Grip' and 'Floating Steps' is?**

Similar to part 1, we have two questions for gauging differences between bars, for which one asks about bars far away from each other, and one about bars next to each other. In the case of this section, the first question contained bars on opposite ends of the x-axis, and this question asks about two bars that sit adjacent to one another. 


```{r echo=F}
default <- def_ratio$def_2
narrower <- nar_ratio$nar_2
wider <- wid_ratio$wid_2

ratio_1_all <- cbind(default, wider, narrower)


noquote(paste('n (default) = ', length(default)))
noquote(paste('n (narrower) = ', length(narrower)))
noquote(paste('n (wider) = ', length(wider)))
noquote(rbind(summary(ratio_1_all), c(paste0('Var    :', round(var(default), 3)), paste0('Var    :', round(var(wider), 3)), paste0('Var    :', round(var(narrower), 3)))))

```
From these statistics we see that altering the axis ratio appears to have even less of an effect than in the first question, with the means of the responses for the default and wider plots being identical, with the mean of the narrower plot responses only 0.157 greater. The medians are identical for all three, along with the IQRs. The variances, however, appear to differ more than the other statistics. 

```{r, echo=F}

brks <- c("Default", "Wider", "Narrower")
vals <- c("#1c9e77", "#d95f02", "#7570b3")

ratio_1_all <- as.data.frame(ratio_1_all)
resp <- c(default, wider, narrower)
type <- c(rep('Default', 70), rep('Wider', 70), rep('Narrower', 70)) 
stats <- data.frame(resp, type)

ggplot(data = stats, aes(x=type, y=resp, fill=type))+
  geom_boxplot(outlier.colour="black", outlier.shape=1,
             outlier.size=2, notch=F)+
  theme_classic()+
  stat_summary(fun=mean, geom="point", shape=15, size=4)+
  scale_fill_manual(breaks = brks, values = vals)+
  scale_y_continuous(labels = seq(1, 7, 1), breaks = seq(1, 7, 1))+
  ylab("Value")+
  xlab("Plot Type")

```
As anticipated from the table of summary statistics, all three IQR boxes are identical with the exception of the slightly higher mean of the responses from the narrower bars as well as differences in the overall range.  


```{r echo=F}

ggplot() +
  geom_density(data = as.data.frame(default ), aes(x=default , col = "Default"))+
  geom_density(data = as.data.frame(wider   ), aes(x=wider   , col = "Wider"))+
  geom_density(data = as.data.frame(narrower), aes(x=narrower, col = "Narrower"))+
  labs(x="Response", y="Density")+
  annotate("text", x = 5, y = 0.63, label = "How large would you say the difference between") +
  annotate("text", x = 5, y = 0.6, label = "'Log Grip' and 'Floating Steps' is?") +
  annotate("text", x = 5, y = 0.55, label = "Whole popualation") +
  scale_x_continuous(limits=c(0, 7))+
  scale_colour_manual(breaks = brks, values = vals)+
  theme_classic()

```

We see all three distributions are very similar, and almost appear to form bell curve shaped distributions, albeit with some irregularities.


**How many times would you say 'Floating Steps' were used?**

This is again similar to question 1 of part 1, where participants were asked to state what they believed to be the height of the bar for 'Salmon Ladder', however this time we choose the third bar from the axis. This is to ascertain whether the distance of the bar from the axis may have an effect alongside any potential perceived distortion of values. Note that the true value was 28.

```{r echo=F}
default <- def_ratio$def_3
narrower <- nar_ratio$nar_3
wider <- wid_ratio$wid_3

ratio_1_all <- cbind(default, wider, narrower)


noquote(paste('n (default) = ', length(default)))
noquote(paste('n (narrower) = ', length(narrower)))
noquote(paste('n (wider) = ', length(wider)))
noquote(rbind(summary(ratio_1_all), c(paste0('Var    :', round(var(default), 3)), paste0('Var    :', round(var(wider), 3)), paste0('Var    :', round(var(narrower), 3)))))

```
We see that the means of each of the three sets of responses are very close to the true value, and the medians are exactly equal to the true value. Based on the means and medians it appears that, once again, altering the axis ratio had minimal, if any, effect on interpretation of the data value. The value for the default plot also appear to be closer to the true value than the control plot in part 1, question 1. 

```{r, echo=F}

brks <- c("Default", "Wider", "Narrower")
vals <- c("#1c9e77", "#d95f02", "#7570b3")

resp <- c(default, wider, narrower)
type <- c(rep('Default', 70), rep('Wider', 70), rep('Narrower', 70)) 
stats <- data.frame(resp, type)

ggplot(data = stats, aes(x=type, y=resp, fill=type))+
  geom_boxplot(outlier.colour="black", outlier.shape=1,
             outlier.size=2, notch=F)+
  theme_classic()+
  stat_summary(fun=mean, geom="point", shape=15, size=4)+
  scale_fill_manual(breaks = brks, values = vals)+
  ylab("Value")+
  xlab("Plot Type")

```

Looking at the box plots, we see very small ranges in the values, signifying that there was a large consensus between respondents in terms of what they perceived the height to be. It can also be seen that there are three outliers below the box plot for the narrower plot responses, and two above for the default plot responses. There is very little overlap between the boxes, and it appears again that there altering the aspect ratio of the bar plot has little to no impact on reading the height of the bar. Additionally, there was less agreement between respondents for the wider plot than for the other two, although this doesn't seem to be too significant.  


```{r echo=F}

ggplot() +
  geom_density(data = as.data.frame(default ), aes(x=default , col = "Default"))+
  geom_density(data = as.data.frame(wider   ), aes(x=wider   , col = "Wider"))+
  geom_density(data = as.data.frame(narrower), aes(x=narrower, col = "Narrower"))+
  labs(x="Response", y="Density")+
  annotate("text", x = 25, y = 1, label = "How many times would you say") +
  annotate("text", x = 25, y = 0.95, label = "'Floating Steps' were used?") +
  annotate("text", x = 25, y = 0.9, label = "Whole popualation", size=3) +
  scale_colour_manual(breaks = brks, values = vals)+
  theme_classic()

```
The distributions for the default and narrower plot responses are very similar, both seeming to be fairly centred on the mean with a steep decrease in density on either side of the mean to very shallow tails within the range $[25, 30]$. The responses for the wider plot appear to be more spread with lower density function values, with a slight negative skew.

Consider now the summary statistics after removing outliers.

```{r echo=F}
default <- default[-which(default >= 30)]
narrower <- narrower[-which(narrower <= 25)]

ratio_1_all <- cbind(default, wider, narrower)


noquote(paste('n (default) = ', length(default)))
noquote(paste('n (narrower) = ', length(narrower)))
noquote(paste('n (wider) = ', length(wider)))
noquote(rbind(summary(ratio_1_all), c(paste0('Var    :', round(var(default), 3)), paste0('Var    :', round(var(wider), 3)), paste0('Var    :', round(var(narrower), 3)))))

```
After removing the outliers the medians have stayed the same, and the mean has obviously decreased for the default and increased for the narrower, however, these means are all still fairly similar to each other and at a first glance prior to testing it again seems that changing the aspect ratio, at least to the degree tested here, is inconsequential to interpretation of the actual value. As expected as well, the variances for the outlier-removed sets have decreased.



**Comparisons**

The last set of questions in part 2 show respondents all three of the bar plots presented in this section and ask them to select which they find most aesthetically pleasing, and which they find easiest and hardest to interpret. Below a table is laid out giving the number of respondents that selected each plot for each of the three questions.

```{r echo=F}
comp_1 <- comp_ratio$all_1
comp_1 <- comp_1[-which(comp_1 == "none")]
comp_2 <- comp_ratio$all_2
comp_3 <- comp_ratio$all_3
tab <- rbind(table(comp_1), table(comp_2), table(comp_3))
rownames(tab) <- c("Which of the three bar charts do you find most aesthetically pleasing?", "Which bar chart do you feel is easiest to read and interpret?", "Which bar chart do you find hardest to read and interpret?")

knitr::kable(tab)
```
For the first question, relating to how aesthetically pleasing respondents found each plot, just over half of the respondents chose the default aspect ratio as the most aesthetically pleasing, with 37 out of the 69 who responded selecting this. 

Similarly, 37 out of the 70 that responded to the second question found the plot with the default aspect ratio easiest to read and interpret. Perhaps the people that preferred this aspect ratio aesthetically did so because they found it easiest to interpret. Investigating this, we find that 27 who chose the default for question 1 also chose this for question 2.

```{r include=F}
cbind(comp_ratio$all_1, comp_ratio$all_2)

count <- 0

for(i in 1:length(comp_ratio$all_1)){
  if (comp_ratio$all_1[i] == "Default" && comp_ratio$all_2[i] == "Default"){
    count <- count + 1
  }
}

count

```

The plot judged hardest to read and interpret by the most respondents was the one with the wider bars, with 30 selecting this and 20 selecting each of the other two. While a significant number chose the default and narrower bars, the slightly higher amount selecting the plot with wider bars matches the previously stated hypothesis formulated from following the Stephen Few paper, which discusses that an ratio of greater width to length could suffer from perceptual imbalance. While we don't see this imbalance in the numbers from the previous questions, the result here does give some indication that the aspect ratio producing wider bars may impact on ease of interpretation.



\subsection{Ninja Warrior - Part 3}

The third and final part of the questions about the American Ninja Warrior data discusses stacked bars and colour schemes. The questions asked in this part are used to decipher how data with multiple categories may be best represented in a bar plot. The plots presented use the same bars as in part 1, but this time we highlight the number of times each obstacle was used in each stage of the competition for each bar.  Each participant was shown both a stacked and a grouped bar plot in one of three colour schemes; the default for the language, viridis, and greyscale. For three versions of the survey, the stacked bars were shown first, and for the other three versions the first shown was the grouped bars. The final question of this part also asked respondents to compare two colour schemes, and through the 6 surveys we have comparisons of every colour scheme against every other colour scheme.

**How many times would you say 'Floating Steps' were used in the Finals (Regional/City) round?**

Again we start with the less subjective question regarding the reading of a numerical value off the axis. In this question we ask about 'Floating Steps', which is the bar third along from the y-axis. The question asks respondents to view the bar plot, where the bars will either be grouped of stacked, and decipher how many times this obstacle was used in the specified round of the competition. The true value for this was 11. The hypothesis for this question is that the respondents will more accurately gauge the value for the grouped bar than the stacked, which as we see below appears to be the case.

```{r echo=F}
vir_stacked_1 <- vir_stacked$vir_sta_1
def_stacked_1 <- def_stacked$def_sta_1
gr_stacked_1 <- gr_stacked$gr_sta_1

vir_grouped_1 <- vir_stacked$vir_dge_1
def_grouped_1 <- def_stacked$def_dge_1
gr_grouped_1 <- gr_stacked$gr_dge_1

stacked_1 <- c(vir_stacked_1, def_stacked_1, gr_stacked_1)
grouped_1 <- c(vir_grouped_1, def_grouped_1, gr_grouped_1)

bars <- data.frame(stacked_1, grouped_1)

noquote(paste('n (stacked) = ', length(stacked_1)))
noquote(paste('n (grouped) = ', length(grouped_1)))

sumy <- summary(bars)
colnames(sumy) <- c("Stacked", "Grouped")
noquote(rbind(sumy, c(paste0('Var    :', round(var(stacked_1), 3)), paste0('Var    :', round(var(grouped_1), 3)))))
```
The mean for the values estimated by respondents using the stacked bars is 14.32, a fair bit larger than the true value of 11, and the mean estimated value for the grouped bars was closer to the true value, at 11.8. The IQR for the grouped bars is also smaller than for the stacked, and comprises of the range $[11, 12]$, insinuating that the estimated values tended to be fairly accurate but with some respondents perhaps slightly overestimating. The IQR for the stacked bars on the other hand covers the interval $[10, 14]$, which does contain the true value, but shows a tendency for both over and underestimation of respondents. Additionally to this, there is a very large variance in the responses to this question, at 54.8 compared to the variance of 13.1 for the responses regarding the grouped bar plots. This adds to the picture that there was much less agreement between respondents, with many straying away from the mean of 14.3. We do see however that the median for both the stacked and grouped bars is 11, showing that the higher mean of the stacked bars may be a result of an influential value at the upper end of the distribution, and that many observations do actually sit around 11. The fact that many values actually sit around 11 could be contributing to the higher variance, as variance is simply the sum of the squared distances from the mean, and so will be elevated if there are many values that sit some distance away from the mean. The higher mean could be reflected in the maximum of the stacked responses being 35, although the maximum of the grouped responses is 40, so there may be more than one influential point in the stacked responses. We can check for outliers by looking at the box plots for this data.

```{r echo=F}
brks <- c("Stacked", "Grouped")
vals <- c("#1c9e77", "#d95f02", "#7570b3")

resp <- c(stacked_1, grouped_1)
type <- c(rep('Stacked', 70), rep('Grouped', 70)) 
stats_2 <- data.frame(resp, type)

ggplot(data = stats_2, aes(x=type, y=resp, fill=type))+
geom_boxplot(outlier.colour="black", outlier.shape=1,
             outlier.size=2, notch=F)+
  theme_classic()+
  stat_summary(fun=mean, geom="point", shape=15, size=4)+
  scale_fill_manual(breaks = brks, values = vals)+
  ylab("Value")+
  xlab("Plot Type")
```
We do in fact see that the box for the grouped responses is very short and centered around 11. The box for the stacked responses shows many high valued outliers that could be causing the mean to be higher, although the IQR is still a fair bit larger than that of the responses for the grouped bars. The mean for this also sits above the IQR, and thus the outliers may be having a significant influence. Now we will remove the outliers assuming, from the box plot, that outliers are any values above or equal to 25 for the stacked responses and above or equal to 20 for the grouped. 

```{r}

stacked_1 <- c(vir_stacked_1, def_stacked_1, gr_stacked_1)
grouped_1 <- c(vir_grouped_1, def_grouped_1, gr_grouped_1)

before_s <- length(stacked_1)
stacked_1 <- stacked_1[-which(stacked_1 >= 25)] 
after_s <- length(stacked_1)

before_g <- length(grouped_1)
grouped_1 <- grouped_1[-which(grouped_1 >= 20)] 
after_g <- length(grouped_1)

n.outliers_s <- before_s-after_s
n.outliers_g <- before_g-after_g

noquote(paste("Number of outliers (stacked):", n.outliers_s))
noquote(paste("Number of outliers (grouped):", n.outliers_g))

sumy <- noquote(rbind(cbind(summary(stacked_1), summary(grouped_1)), c(paste0('Var    :', round(var(stacked_1), 3)), paste0('Var    :', round(var(grouped_1), 3)))))
colnames(sumy) <- c("Stacked", "Grouped")
sumy
```
We see that removing the outliers as specified by the box plot, the mean of the stacked responses is now just above 11, and actually closer to the true value than the mean of the other set of responses, and the median has decreased to 10. From this one could infer that there is no difference between each type of bar plot in terms of gauging the size of the bars. However, we see that there are 12 outliers in the stacked responses, which leads to the idea that these are not in fact all outliers and may be valid responses that just sit on the upper end of the distribution. However, it seems the cause of the high values could be respondents taking the whole height of the bar, which has an actual height of 28, rather than the section of interest. Many of the potentially influential values fall around the range $[25, 30]$, with all but 2 of the 12 potential outliers sitting in this interval, with the remaining two both being 35. Looking below at the summary statistics for only the values picked up as outliers, we see a mean of 29.83, which is higher than the true value of 28, and interestingly goes against the analysis from part 1, question 2 whereby respondents were asked to judge the height of this bar and on average underestimated. The fact that so many participants misinterpreted this plot and signify that stacked bar plots may not be the best way to present data to general public, as there may be the potential to misread the height of the whole bar as the size of the top category.


```{r}

vir_stacked_1 <- vir_stacked$vir_sta_1
def_stacked_1 <- def_stacked$def_sta_1
gr_stacked_1 <- gr_stacked$gr_sta_1

vir_grouped_1 <- vir_stacked$vir_dge_1
def_grouped_1 <- def_stacked$def_dge_1
gr_grouped_1 <- gr_stacked$gr_dge_1

stacked_1 <- c(vir_stacked_1, def_stacked_1, gr_stacked_1)
grouped_1 <- c(vir_grouped_1, def_grouped_1, gr_grouped_1)

stacked_1 <- stacked_1[which(stacked_1 >= 25)] 

summary(stacked_1)

stacked_1 <- c(vir_stacked_1, def_stacked_1, gr_stacked_1)
stacked_1 <- stacked_1[-which(stacked_1 >= 25)]
grouped_1 <- c(vir_grouped_1, def_grouped_1, gr_grouped_1) 
```
As a result of this, we will discount this set of 12 values from the analysis, and thus come to the conclusion that, for the respondents that appear to have judged the height of the correct section, there was little to no impact when using stacked vs grouped bar charts, and most of the difference comes from misinterpretation of the plot itself, as opposed to a poorer judgment of size.

To see if either of these values are significantly far from the true value, we once again run tests. Firstly, run Shapiro tests to test for normality.

\textbf{Shapiro test for the responses for the stacked bar plot}
```{r}
shapiro.test(stacked_1)
```

\textbf{Shapiro test for the responses for the stacked bar plot}
```{r}
shapiro.test(grouped_1)
```
The small p-values signify that this data is not normal, and a look at the summary statistics tells us neither is symmetric about the mean. Thus, as in question 1, we run sign tests, alongside the t-tests on samples from a normal distribution with mean and variance equal to out data. We will test against a median of 11 for the sign tests, and a mean of 11 for the t-tests. 

\textbf{Sign test for the responses for the stacked bar plot}
```{r}
SIGN.test(stacked_1, md=11, alternative="t")
```
This test gives a high p value of 0.5258, showing that for the stacked bar plot responses (after removing the values as priorly specified), the participant estimated values do not differ significantly from the true value.

\textbf{Sign test for the responses for the grouped bar plot}
```{r}
SIGN.test(grouped_1, md=11, alternative="t")
```
For the grouped bar plot we have a p value of 0.009 < 0.05, and thus these responses are statistically significantly different from the true value. 
```{r}
noquote(paste("*CONTROL*"))
means <- rep(NA, 100)
for(i in 1:100){
  samp <- rnorm(100, mean=mean(stacked_1), sd=sd(stacked_1))
  means[i] <- mean(samp)
}
t.test(means, mu=11)

noquote(paste("*TRUNCATED*"))
means <- rep(NA, 100)
for(i in 1:100){
  samp <- rnorm(100, mean=mean(grouped_1), sd=sd(grouped_1))
  means[i] <- mean(samp)
}
t.test(means, mu=11)

```
Running t-tests on the means, however, we see both sets of responses differ statistically significantly from the true value.

**How many times would you say 'Log Grip' was used in the Finals (Regional/City) round?**

This question is similar the above, but for the next bar to the right. The purpose of this question was to test the same hypothesis as the previous question, and also to lead into the following question, where respondents were asked to compare the 'Floating Steps' and 'Log Grip'. Additionally, the bar in the previous question had only two categories, of which the respondents were asked to judge the size of the category on the top of the bar in the stacked plot, whereas the bar for 'Log Grip' has 5 categories, of which the category of interest sits above 4. The true value of this was 9.

```{r echo=F}
vir_stacked_2 <- vir_stacked$vir_sta_2
def_stacked_2 <- def_stacked$def_sta_2
gr_stacked_2 <- gr_stacked$gr_sta_2

vir_grouped_2 <- vir_stacked$vir_dge_2
def_grouped_2 <- def_stacked$def_dge_2
gr_grouped_2 <- gr_stacked$gr_dge_2

stacked_2 <- c(vir_stacked_2, def_stacked_2, gr_stacked_2)
grouped_2 <- c(vir_grouped_2, def_grouped_2, gr_grouped_2)

bars <- data.frame(stacked_2, grouped_2)

noquote(paste('n (stacked) = ', length(stacked_2)))
noquote(paste('n (grouped) = ', length(grouped_2)))

sumy <- summary(bars)
colnames(sumy) <- c("Stacked", "Grouped")
noquote(rbind(sumy, c(paste0('Var    :', round(var(stacked_2), 3)), paste0('Var    :', round(var(grouped_2), 3)))))
```
Similarly to the previous question, we see that the mean response for the stacked bar plots are higher than that of the grouped, and the mean of the stacked also slightly overestimates the value. Once again however, we appear to see a selection of respondents judging the full height of the bar rather than the category as asked. Looking at the data, the interval for these responses seems to be $[20, 25]$, as the next response below 20 is a value of 10, seeming to separate the data into two separate subsets. This can be confirmed by a box plot. 

```{r echo=F}
brks <- c("Stacked", "Grouped")
vals <- c("#1c9e77", "#d95f02", "#7570b3")

resp <- c(stacked_2, grouped_2)
type <- c(rep('Stacked', 70), rep('Grouped', 70)) 
stats_2 <- data.frame(resp, type)

ggplot(data = stats_2, aes(x=type, y=resp, fill=type))+
geom_boxplot(outlier.colour="black", outlier.shape=1,
             outlier.size=2, notch=F)+
  theme_classic()+
  stat_summary(fun=mean, geom="point", shape=15, size=4)+
  scale_fill_manual(breaks = brks, values = vals)+
  ylab("Value")+
  xlab("Plot Type")
```
We indeed see that the distribution of values for each of the two response sets appears to be almost identical with the exception of outliers at and above 20 for the box plot of responses for the stacked bar plot. Thus we view the sets of summary statistics for the two but with these values removed. 

```{r}

stacked_2 <- c(vir_stacked_2, def_stacked_2, gr_stacked_2)
grouped_2 <- c(vir_grouped_2, def_grouped_2, gr_grouped_2)

before_s <- length(stacked_2)
stacked_2 <- stacked_2[-which(stacked_2 >= 20)] 
after_s <- length(stacked_2)

n.outliers_s <- before_s-after_s
n.outliers_g <- before_g-after_g

noquote(paste("Number of outliers (stacked):", n.outliers_s))
noquote(paste("Number of outliers (grouped):", n.outliers_g))

sumy <- noquote(rbind(cbind(summary(stacked_2), summary(grouped_2)), c(paste0('Var    :', round(var(stacked_2), 3)), paste0('Var    :', round(var(grouped_2), 3)))))
colnames(sumy) <- c("Stacked", "Grouped")
sumy
```
Here we see that there tended to be a slight underestimation in the value for the stacked bar plot, however this is approximately 0.46 away from the true value, and unlikely to be significant. This can again be tested as above, where it is less clear whether the data are symmetric, so we will also run symmetry test.

\textbf{Shapiro test for the responses for the stacked bar plot}
```{r}
shapiro.test(stacked_2)
symmetry.test(stacked_2)
```

\textbf{Shapiro test for the responses for the stacked bar plot}
```{r}
shapiro.test(grouped_2)
symmetry.test(grouped_2)
```
Once again we see that the response sets are non-normally distributed and asymmetric, and so sign tests are once again applicable. 

\textbf{Sign test for the responses for the stacked bar plot}
```{r}
SIGN.test(stacked_2, md=9, alternative="t")
```
Here we see a p value of around 0.04, which shows a statistically significant difference in the responses from the true value of 9 at the 0.05 level of significance. However, this would very easily become insignificant by slightly lowering the significance level to, say, 0.035.

\textbf{Sign test for the responses for the grouped bar plot}
```{r}
SIGN.test(grouped_2, md=9, alternative="t")
```
Once again, this shows a significant p value, but this would once again be classes as insignificant at, for example, a 0.01 level of significance.

```{r}
noquote(paste("*CONTROL*"))
means <- rep(NA, 100)
for(i in 1:100){
  samp <- rnorm(100, mean=mean(stacked_2), sd=sd(stacked_2))
  means[i] <- mean(samp)
}
t.test(means, mu=9)

noquote(paste("*TRUNCATED*"))
means <- rep(NA, 100)
for(i in 1:100){
  samp <- rnorm(100, mean=mean(grouped_2), sd=sd(grouped_2))
  means[i] <- mean(samp)
}
t.test(means, mu=9)

```


**Please select the statement you feel applies to the bar chart above.**

```{r echo=F}
vir_stacked_3 <- vir_stacked$vir_sta_3
def_stacked_3 <- def_stacked$def_sta_3
gr_stacked_3 <- gr_stacked$gr_sta_3

vir_dodged_3 <- vir_stacked$vir_dge_3
def_dodged_3 <- def_stacked$def_dge_3
gr_dodged_3 <- gr_stacked$gr_dge_3

stacked_3 <- c(vir_stacked_3, def_stacked_3, gr_stacked_3)
dodged_3 <- c(vir_dodged_3, def_dodged_3, gr_dodged_3)

tab <- rbind(table(stacked_3), table(dodged_3))
rownames(tab) <- c("Stacked", "Grouped")
colnames(tab) <- c("Equal", "Less", "More")
tab
```

**Which obstacle do you think was used MORE in Finals (Regional/City) rounds, 'Log Grip' or 'Floating Steps'?**

```{r echo=F}
vir_stacked_4 <- vir_stacked$vir_sta_4
def_stacked_4 <- def_stacked$def_sta_4
gr_stacked_4 <- gr_stacked$gr_sta_4

vir_dodged_4 <- vir_stacked$vir_dge_4
def_dodged_4 <- def_stacked$def_dge_4
gr_dodged_4 <- gr_stacked$gr_dge_4

stacked_4 <- c(vir_stacked_4, def_stacked_4, gr_stacked_4)
dodged_4 <- c(vir_dodged_4, def_dodged_4, gr_dodged_4)

tab <- rbind(table(stacked_4), table(dodged_4))
rownames(tab) <- c("Stacked", "Grouped")
colnames(tab) <- c("Equal", "Less", "More")
tab
```


**Which bar chart do you feel is easiest to read and interpret?**

```{r echo=F}
a_1 <- set_a$sta_dge
b_1 <- set_b$sta_dge
c_1 <- set_c$sta_dge
d_1 <- set_d$sta_dge
e_1 <- set_e$sta_dge
f_1 <- set_f$sta_dge

for(i in 1:length(a_1)){
  if(a_1[i] == "A"){
    a_1[i] <- "Stacked"
  } else a_1[i] <- "Grouped"
}

for(i in 1:length(b_1)){
  if(b_1[i] == "A"){
    b_1[i] <- "Stacked"
  } else b_1[i] <- "Grouped"
}

for(i in 1:length(d_1)){ 
  if(d_1[i] == "A"){
    d_1[i] <- "Stacked"
  } else d_1[i] <- "Grouped"
}

for(i in 1:length(c_1)){
  if(c_1[i] == "B"){
    c_1[i] <- "Stacked"
  } else c_1[i] <- "Grouped"
}

for(i in 1:length(e_1)){
  if(e_1[i] == "B"){
    e_1[i] <- "Stacked"
  } else e_1[i] <- "Grouped"
}

for(i in 1:length(f_1)){
  if(f_1[i] == "B"){
    f_1[i] <- "Stacked"
  } else f_1[i] <- "Grouped"
}

tab <- table(c(a_1, b_1, c_1, d_1, e_1, f_1))
tab
```

``` {r, echo=F}
tab <- rbind(table(a_1), table(b_1), table(c_1), table(d_1), table(e_1), table(f_1))
rownames(tab) <- c("Set A", "Set B", "Set C", "Set D", "Set E", "Set F")
tab
```


**Which colour scheme do you find most aesthetically pleasing?**

```{r echo=F}
a_1 <- set_a$sta_dge
b_1 <- set_b$sta_dge
c_1 <- set_c$sta_dge
d_1 <- set_d$sta_dge
e_1 <- set_e$sta_dge
f_1 <- set_f$sta_dge

tab <- rbind(table(a_1), table(b_1), table(c_1), table(d_1), table(e_1), table(f_1))
rownames(tab) <- c("Set A", "Set B", "Set C", "Set D", "Set E", "Set F")
tab
```


**Do you feel that one of the colour schemes makes it easier to read and interpret? If so, please select which one.**

```{r echo=F}
a_1 <- set_a$a_cols_1
b_1 <- set_b$b_cols_1
c_1 <- set_c$c_cols_1
d_1 <- set_d$d_cols_1
e_1 <- set_e$e_cols_1
f_1 <- set_f$f_cols_1

for(i in 1:length(a_1)){
  if(a_1[i] == "A"){
    a_1[i] <- "Dark2"
  } else a_1[i] <- "Default"
}

for(i in 1:length(b_1)){
  if(b_1[i] == "B"){
    b_1[i] <- "Dark2"
  } else b_1[i] <- "Default"
}

for(i in 1:length(e_1)){
  if(e_1[i] == "A"){
    e_1[i] <- "Dark2"
  } else e_1[i] <- "Greyscale"
}

for(i in 1:length(f_1)){
  if(f_1[i] == "B"){
    f_1[i] <- "Dark2"
  } else f_1[i] <- "Greyscale"
}

for(i in 1:length(c_1)){
  if(c_1[i] == "A"){
    c_1[i] <- "Default"
  } else c_1[i] <- "Greyscale"
}

for(i in 1:length(d_1)){
  if(d_1[i] == "A"){
    d_1[i] <- "Greyscale"
  } else d_1[i] <- "Default"
}

tab <- table(c(a_1, b_1, c_1, d_1, e_1, f_1))
tab
```

```{r echo=F}
tab <- table(c(a_1, b_1))
tab
```

```{r echo=F}
tab <- table(c(c_1, d_1))
tab
```

```{r echo=F}
tab <- table(c(e_1, f_1))
tab
```


\subsection{Sales - Part 1}


**How much would you say sales of each company increased between January and December? [Company A]**

```{r echo=F}
sep_1a <- na.exclude(ab_sep$sep_1a)
trn_1a <- ab_trn$ab_trn_1a
zro_1a <- ab_zero$ab_zro_1

for(i in 1:length(sep_1a)){
  if(sep_1a[i] == "1 (A little)"){
    sep_1a[i] <- "1"
  }
  if(sep_1a[i] == "7 (A lot)"){
    sep_1a[i] <- "7"
  }
}

for(i in 1:length(trn_1a)){
  if(trn_1a[i] == "1 (A little)"){
    trn_1a[i] <- "1"
  }
  if(trn_1a[i] == "7 (A lot)"){
    trn_1a[i] <- "7"
  }
}

for(i in 1:length(zro_1a)){
  if(zro_1a[i] == "1 (A little)"){
    zro_1a[i] <- "1"
  }
  if(zro_1a[i] == "7 (A lot)"){
    zro_1a[i] <- "7"
  }
}

sep_1a <- as.numeric(sep_1a)
trn_1a <- as.numeric(trn_1a)
zro_1a <- as.numeric(zro_1a)

sumy <- cbind(summary(sep_1a), summary(trn_1a), summary(zro_1a))
colnames(sumy) <- c("Separate", "Truncated", "Zeroed")

sumy

```


**How much would you say sales of each company increased between January and December? [Company B]**

```{r echo=F}
sep_1b <- na.exclude(ab_sep$sep_1b)
trn_1b <- na.exclude(ab_trn$ab_trn_1b)
zro_1b <- na.exclude(ab_zero$ab_zro_1b)

for(i in 1:length(sep_1b)){
  if(sep_1b[i] == "1 (A little)"){
    sep_1b[i] <- "1"
  }
  if(sep_1b[i] == "7 (A lot)"){
    sep_1b[i] <- "7"
  }
}

for(i in 1:length(trn_1b)){
  if(trn_1b[i] == "1 (A little)"){
    trn_1b[i] <- "1"
  }
  if(trn_1b[i] == "7 (A lot)"){
    trn_1b[i] <- "7"
  }
}

for(i in 1:length(zro_1b)){
  if(zro_1b[i] == "1 (A little)"){
    zro_1b[i] <- "1"
  }
  if(zro_1b[i] == "7 (A lot)"){
    zro_1b[i] <- "7"
  }
}

sep_1b <- as.numeric(sep_1b)
trn_1b <- as.numeric(trn_1b)
zro_1b <- as.numeric(zro_1b)

sumy <- cbind(summary(sep_1b), summary(trn_1b), summary(zro_1b))
colnames(sumy) <- c("Separate", "Truncated", "Zeroed")

sumy

```


**How large would you say the drop in sales between April and July of Company A  is?**

```{r echo=F}
sep_2 <- na.exclude(ab_sep$sep_2)
trn_2 <- na.exclude(ab_trn$ab_trn_2)
zro_2 <- na.exclude(ab_zero$ab_zro_2)

sumy <- cbind(summary(sep_2), summary(trn_2), summary(zro_2))
colnames(sumy) <- c("Separate", "Truncated", "Zeroed")

sumy

```

\subsection{Sales - Part 2}

**Based on the above graph, how large would you say the difference is between the number of sales Company C makes and the number of sales Company D makes?**


```{r echo=F}
trn_cd <- na.exclude(cd_trn$cd_trn)
zro_cd <- na.exclude(cd_zro$cd_zro)

sumy <- cbind(summary(trn_cd), summary(zro_cd))
colnames(sumy) <- c("Truncated", "Zeroed")

sumy

```





















